{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7768fd51-9f7b-4fd1-89f7-ce9bb3043009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "41a6217c-7087-4837-8f49-17e63cf13968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.layers import  Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aabf74bb-a1c9-4222-a454-9b31c8d8a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lagged_all = pd.read_parquet(\"data/processed/df_lagged_30_all.parquet\")\n",
    "df_lagged_all = pd.read_parquet(\"data/processed/df_lagged_all.parquet\")\n",
    "df_2_full = pd.read_parquet(\"data/processed/df_2_full_v2.parquet\")\n",
    "\n",
    "df_all=pd.read_parquet(\"data/processed/df_all.parquet\")\n",
    "df_all_peak= df_all.set_index(\"Datetime\").between_time(\"07:15\", \"08:30\").reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800c31a-39c9-40dc-ae2a-76cfb88fe05d",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac797839-78ec-4f39-b417-f351d8b13d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sensor = 1076\n",
    "same_portal=\"55620\"\n",
    "neighbour_portal = \"56160\"\n",
    "\n",
    "same_portal_sensors = df_2_full[df_2_full['PORTAL_clean'] == same_portal]['DP_ID'].unique()\n",
    "same_sensors = [s for s in same_portal_sensors if s != target_sensor]\n",
    "\n",
    "\n",
    "neighbour_sensors = df_2_full[df_2_full['PORTAL_clean'] == neighbour_portal]['DP_ID'].unique()\n",
    "all_sensors=df_2_full['DP_ID'].unique()\n",
    "except_target_sensors = [s for s in all_sensors if s != target_sensor]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f5972f6-5842-446d-8b73-a14928be0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlags=15\n",
    "#nlags=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c8be1197-b68b-4342-bb05-ac2585afcee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_features_same_nl = [\n",
    "    f'SENSOR_{sensor}_FLOW'\n",
    "    for sensor in same_sensors\n",
    "\n",
    "]\n",
    "flow_features_neighbour_nl = [\n",
    "    f'SENSOR_{sensor}_FLOW'\n",
    "    for sensor in neighbour_sensors\n",
    "\n",
    "]\n",
    "speed_features_same_nl = [\n",
    "    f'SENSOR_{sensor}_SPEED'\n",
    "    for sensor in same_sensors\n",
    "]\n",
    "speed_features_neighbour_nl = [\n",
    "    f'SENSOR_{sensor}_SPEED'\n",
    "    for sensor in neighbour_sensors\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3c27edb9-8c27-4658-8c63-b99c6a27ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_features_same = [\n",
    "    f'SENSOR_{sensor}_FLOW_lag_{i+1}'\n",
    "    for sensor in same_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "flow_features_neighbour = [\n",
    "    f'SENSOR_{sensor}_FLOW_lag_{i+1}'\n",
    "    for sensor in neighbour_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "speed_features_same = [\n",
    "    f'SENSOR_{sensor}_SPEED_lag_{i+1}'\n",
    "    for sensor in same_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "speed_features_neighbour = [\n",
    "    f'SENSOR_{sensor}_SPEED_lag_{i+1}'\n",
    "    for sensor in neighbour_sensors\n",
    "    for i in range(nlags)\n",
    "]        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d9c83-9cd0-4199-9499-f26cd2591ba6",
   "metadata": {},
   "source": [
    "Train -Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a65de289-ff0f-4bbc-bca0-7a623f17634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_lagged_all, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094f6e5-8717-4767-9c9d-4d1d54ba1df1",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2fb15998-0cb4-44b3-9f74-96d1f0f055f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/scaler_speed_neighbour.pkl']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FLOW same\n",
    "scaler_flow_same = StandardScaler()\n",
    "X_train_scaled_flow_same = scaler_flow_same.fit_transform(df_train[flow_features_same])\n",
    "X_test_scaled_flow_same  = scaler_flow_same.transform(df_test[flow_features_same])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_flow_same.pkl\")\n",
    "\n",
    "# SPEED same\n",
    "scaler_speed_same = StandardScaler()\n",
    "X_train_scaled_speed_same = scaler_speed_same.fit_transform(df_train[speed_features_same])\n",
    "X_test_scaled_speed_same  = scaler_speed_same.transform(df_test[speed_features_same])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_speed_same.pkl\")\n",
    "\n",
    "\n",
    "# FLOW neighbour\n",
    "scaler_flow_neigh = StandardScaler()\n",
    "X_train_scaled_flow_neighbour = scaler_flow_neigh.fit_transform(df_train[flow_features_neighbour])\n",
    "X_test_scaled_flow_neighbour  = scaler_flow_neigh.transform(df_test[flow_features_neighbour])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_flow_neighbour.pkl\")\n",
    "\n",
    "\n",
    "# SPEED neighbour\n",
    "scaler_speed_neighbour = StandardScaler()\n",
    "X_train_scaled_speed_neighbour = scaler_speed_neighbour.fit_transform(df_train[speed_features_neighbour])\n",
    "X_test_scaled_speed_neighbour  = scaler_speed_neighbour.transform(df_test[speed_features_neighbour])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_speed_neighbour.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a00541-0469-42b8-a950-2daae50434df",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "043ba35f-8f5f-489e-a7af-b4a4bc811cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Linear Regression (FLOW) -> RMSE: 33.543, MAE: 23.809, R2: 0.836\n",
      "Baseline Linear Regression (SPEED) -> RMSE: 0.861, MAE: 0.462, R2: 0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#same portal\n",
    "model_flow = LinearRegression()\n",
    "model_flow.fit(df_train[flow_features_same], df_train['FLOW_future_sum'])\n",
    "\n",
    "model_speed = LinearRegression()\n",
    "model_speed.fit(df_train[speed_features_same], df_train['SPEED_future_mean'])\n",
    "\n",
    "\n",
    "# Vorhersage\n",
    "y_pred = model_flow.predict(df_test[flow_features_same])\n",
    "y_test=df_test['FLOW_future_sum']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Linear Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(df_test[speed_features_same])\n",
    "y_test=df_test['SPEED_future_mean']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Linear Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "369fcdfe-4284-4b49-9dd6-3eb9388b1d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Linear Regression (FLOW) -> RMSE: 28.474, MAE: 19.559, R2: 0.882\n",
      "Baseline Linear Regression (SPEED) -> RMSE: 1.051, MAE: 0.513, R2: 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#neighbour portal\n",
    "model_flow = LinearRegression()\n",
    "model_flow.fit(df_train[flow_features_neighbour], df_train['FLOW_future_sum'])\n",
    "\n",
    "model_speed = LinearRegression()\n",
    "model_speed.fit(df_train[speed_features_neighbour], df_train['SPEED_future_mean'])\n",
    "\n",
    "\n",
    "#prediction\n",
    "y_pred = model_flow.predict(df_test[flow_features_neighbour])\n",
    "y_test=df_test['FLOW_future_sum']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Linear Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(df_test[speed_features_neighbour])\n",
    "y_test=df_test['SPEED_future_mean']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Linear Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1d7de0-5c50-4357-b051-e5aeae37c355",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "15c2a55a-86fe-4c42-b719-43075c777f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression (FLOW) -> RMSE: 28.647, MAE: 20.634, R²: 0.880\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.810, MAE: 0.401, R²: 0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_flow = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model_flow.fit(df_train[flow_features_same], df_train['FLOW_future_sum'])\n",
    "\n",
    "model_speed = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model_speed.fit(df_train[speed_features_same], df_train['SPEED_future_mean'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model_flow.predict(df_test[flow_features_same])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "y_pred = model_speed.predict(df_test[speed_features_same])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6420ac2f-841e-431d-aed5-ce0cc6a5f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression (FLOW) -> RMSE: 24.460, MAE: 17.192, R²: 0.913\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.936, MAE: 0.424, R²: 0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_flow = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model_flow.fit(df_train[flow_features_neighbour], df_train['FLOW_future_sum'])\n",
    "\n",
    "model_speed = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model_speed.fit(df_train[speed_features_neighbour], df_train['SPEED_future_mean'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model_flow.predict(df_test[flow_features_neighbour])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "y_pred = model_speed.predict(df_test[speed_features_neighbour])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2466b25-b0cf-45cb-b70b-70174bae1b91",
   "metadata": {},
   "source": [
    "xgboost with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f1cf3a3b-e25d-425b-bd55-9a52baf9e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.001,0.005,0.01, 0.05],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c270770f-9afd-4e21-99a1-bd01467fbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\"Type\", \"MAE\", \"RMSE\", \"R²\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2c63e4f9-e64a-4537-955f-3049a609bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_result(results_df, type, y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "\n",
    "    new_row = {\n",
    "        \"Type\": type,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R²\": r2\n",
    "    }\n",
    "\n",
    "    return pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b359e1cf-6971-4402-8351-98cabfaa939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Beste Parameter (FLOW): {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "XGBoost Regression (FLOW) -> RMSE: 28.311, MAE: 20.292, R²: 0.883\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\1773143569.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter (FLOW): {'subsample': 0.6, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.812, MAE: 0.401, R²: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#same portal\n",
    "random_search_flow = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30, \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "random_search_flow.fit(df_train[flow_features_same], df_train[\"FLOW_future_sum\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_flow.best_params_)\n",
    "model_flow = random_search_flow.best_estimator_\n",
    "model_flow.save_model(\"model/xgb_flow_same.json\")\n",
    "\n",
    "features_used = df_train[flow_features_same].columns.tolist()\n",
    "joblib.dump(features_used, \"model/features_flow_same.pkl\")\n",
    "\n",
    "y_pred = model_flow.predict(df_test[flow_features_same])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "results_df = add_result(results_df, \"FLOW -same portal\", y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "random_search_speed = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "\n",
    "random_search_speed.fit(df_train[speed_features_same], df_train[\"SPEED_future_mean\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_speed.best_params_)\n",
    "model_speed = random_search_speed.best_estimator_\n",
    "model_speed.save_model(\"model/xgb_speed_same.json\")\n",
    "\n",
    "features_used = df_train[speed_features_same].columns.tolist()\n",
    "joblib.dump(features_used, \"model/features_speed_same.pkl\")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(df_test[speed_features_same])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "results_df = add_result(results_df, \"SPEED -same portal\", y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8c16d6f1-4dd1-4fac-a0d5-19846c3a7caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Beste Parameter (FLOW): {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (FLOW) -> RMSE: 24.096, MAE: 16.871, R²: 0.915\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter (FLOW): {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.930, MAE: 0.420, R²: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#neighbour portal\n",
    "random_search_flow = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "random_search_flow.fit(df_train[flow_features_neighbour], df_train[\"FLOW_future_sum\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_flow.best_params_)\n",
    "model_flow = random_search_flow.best_estimator_\n",
    "model_flow.save_model(\"model/xgb_flow_neighbour.json\")\n",
    "\n",
    "features_used = df_train[flow_features_neighbour].columns.tolist()\n",
    "joblib.dump(features_used, \"model/features_flow_neighbour.pkl\")\n",
    "\n",
    "\n",
    "y_pred = model_flow.predict(df_test[flow_features_neighbour])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "results_df = add_result(results_df, \"FLOW -neighbour portal\", y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "random_search_speed = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30, \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "\n",
    "random_search_speed.fit(df_train[speed_features_neighbour], df_train[\"SPEED_future_mean\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_speed.best_params_)\n",
    "model_speed = random_search_speed.best_estimator_\n",
    "model_speed.save_model(\"model/xgb_speed_neighbour.json\")\n",
    "\n",
    "features_used = df_train[speed_features_neighbour].columns.tolist()\n",
    "joblib.dump(features_used, \"model/features_speed_neighbour.pkl\")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(df_test[speed_features_neighbour])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "results_df = add_result(results_df, \"SPEED -neighbour portal\", y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "66aaf3cf-e402-4db6-a26a-1b91144357f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLOW -neighbour portal</td>\n",
       "      <td>16.871492</td>\n",
       "      <td>24.095540</td>\n",
       "      <td>0.915146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLOW -same portal</td>\n",
       "      <td>20.291550</td>\n",
       "      <td>28.310582</td>\n",
       "      <td>0.882863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPEED -neighbour portal</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.930045</td>\n",
       "      <td>0.659704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPEED -same portal</td>\n",
       "      <td>0.401327</td>\n",
       "      <td>0.812237</td>\n",
       "      <td>0.740454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Type        MAE       RMSE        R²\n",
       "2   FLOW -neighbour portal  16.871492  24.095540  0.915146\n",
       "0        FLOW -same portal  20.291550  28.310582  0.882863\n",
       "3  SPEED -neighbour portal   0.419800   0.930045  0.659704\n",
       "1       SPEED -same portal   0.401327   0.812237  0.740454"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f597a15-b86d-4f1f-9416-95e166f15ad4",
   "metadata": {},
   "source": [
    "Feedforward Neural Network (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "14177efa-8919-49c5-9c1c-5b69343236dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast forward NN (FLOW) -> RMSE: 29.248, MAE: 20.778, R²: 0.875\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Fast forward NN (SPEED) -> RMSE: 0.819, MAE: 0.433, R²: 0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#same portal \n",
    "\n",
    "model_flow= Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled_flow_same.shape[1],)),  \n",
    "    Dense(32, activation='relu'),                                           \n",
    "    Dense(16, activation='relu'),                                         \n",
    "    Dense(1)                                                              \n",
    "])\n",
    "\n",
    "model_flow.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history_flow = model_flow.fit(\n",
    "    X_train_scaled_flow_same, df_train[\"FLOW_future_sum\"],\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model_flow.predict(X_test_scaled_flow_same)\n",
    "y_test=df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "model_speed = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled_speed_same.shape[1],)),  \n",
    "    Dense(32, activation='relu'),                                          \n",
    "    Dense(16, activation='relu'),                                           \n",
    "    Dense(1)                                                                \n",
    "])\n",
    "\n",
    "model_speed.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history_speed = model_speed.fit(\n",
    "    X_train_scaled_speed_same, df_train[\"SPEED_future_mean\"],\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(X_test_scaled_speed_same)\n",
    "y_test=df_test[\"SPEED_future_mean\"]\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ca849db4-1240-4f02-947c-5ea3869862ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Fast forward NN (FLOW) -> RMSE: 24.794, MAE: 17.303, R²: 0.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fast forward NN (SPEED) -> RMSE: 0.969, MAE: 0.458, R²: 0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#neighbour portal\n",
    "model_flow= Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled_flow_neighbour.shape[1],)),  \n",
    "    Dense(32, activation='relu'),                                           \n",
    "    Dense(16, activation='relu'),                                           \n",
    "    Dense(1)                                                                 \n",
    "])\n",
    "\n",
    "model_flow.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history_flow = model_flow.fit(\n",
    "    X_train_scaled_flow_neighbour, df_train[\"FLOW_future_sum\"],\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model_flow.predict(X_test_scaled_flow_neighbour)\n",
    "y_test=df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "model_speed = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled_speed_neighbour.shape[1],)), \n",
    "    Dense(32, activation='relu'),                          \n",
    "    Dense(16, activation='relu'),         \n",
    "    Dense(1)                                                   \n",
    "])\n",
    "\n",
    "model_speed.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history_speed = model_speed.fit(\n",
    "    X_train_scaled_speed_neighbour, df_train[\"SPEED_future_mean\"],\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(X_test_scaled_speed_neighbour)\n",
    "y_test=df_test[\"SPEED_future_mean\"]\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d7b75-0f26-460f-8d14-8cd72a2ea300",
   "metadata": {},
   "source": [
    "NN with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d48647a9-4747-4637-a548-8335a8094185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\308595228.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse   val_rmse\n",
      "0              16             2          0.00   29.371403  29.733335\n",
      "1              16             2          0.05   37.075043  33.153324\n",
      "2              16             2          0.10   42.041279  33.635246\n",
      "3              16             3          0.00   27.912714  28.976200\n",
      "4              16             3          0.05   39.897415  33.503639\n",
      "5              16             3          0.10   43.846443  34.295017\n",
      "6              16             4          0.00   28.486589  29.510708\n",
      "7              16             4          0.05   36.866894  31.401754\n",
      "8              16             4          0.10   40.082947  31.197016\n",
      "9              32             2          0.00   28.014595  29.070684\n",
      "10             32             2          0.05   32.399998  30.271238\n",
      "11             32             2          0.10   34.075420  30.764746\n",
      "12             32             3          0.00   27.727701  29.272102\n",
      "13             32             3          0.05   32.647373  30.021769\n",
      "14             32             3          0.10   35.011250  31.629435\n",
      "15             32             4          0.00   28.093256  29.142313\n",
      "16             32             4          0.05   31.315088  29.387403\n",
      "17             32             4          0.10   35.715744  31.192465\n",
      "18             64             2          0.00   27.472795  29.341480\n",
      "19             64             2          0.05   32.532330  30.811172\n",
      "20             64             2          0.10   33.490093  30.293657\n",
      "21             64             3          0.00   28.851919  29.869560\n",
      "22             64             3          0.05   30.222097  29.404978\n",
      "23             64             3          0.10   31.837008  29.717525\n",
      "24             64             4          0.00   27.025183  28.974485\n",
      "25             64             4          0.05   30.128540  29.311167\n",
      "26             64             4          0.10   32.301857  29.614431\n",
      "27            128             2          0.00   27.893883  29.641785\n",
      "28            128             2          0.05   30.282890  29.778042\n",
      "29            128             2          0.10   31.468235  30.192453\n",
      "30            128             3          0.00   27.376104  29.253227\n",
      "31            128             3          0.05   28.109545  28.893290\n",
      "32            128             3          0.10   28.693462  29.138802\n",
      "33            128             4          0.00   28.150019  29.234877\n",
      "34            128             4          0.05   29.346590  29.468685\n",
      "35            128             4          0.10   30.588945  29.653276\n",
      "Epoch 1/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 891us/step - loss: 1731.5171 - rmse: 41.6115 - val_loss: 1050.1238 - val_rmse: 32.4056 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - loss: 1095.2737 - rmse: 33.0949 - val_loss: 1041.9083 - val_rmse: 32.2786 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - loss: 1052.7274 - rmse: 32.4458 - val_loss: 964.5223 - val_rmse: 31.0568 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - loss: 1027.7020 - rmse: 32.0578 - val_loss: 976.1412 - val_rmse: 31.2433 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 994.6746 - rmse: 31.5385 - val_loss: 1033.4736 - val_rmse: 32.1477 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - loss: 981.7228 - rmse: 31.3325 - val_loss: 985.1785 - val_rmse: 31.3876 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 914.6654 - rmse: 30.2434 - val_loss: 898.3356 - val_rmse: 29.9722 - learning_rate: 0.0050\n",
      "Epoch 8/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 913.1998 - rmse: 30.2192 - val_loss: 908.3728 - val_rmse: 30.1392 - learning_rate: 0.0050\n",
      "Epoch 9/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - loss: 905.7272 - rmse: 30.0953 - val_loss: 921.6393 - val_rmse: 30.3585 - learning_rate: 0.0050\n",
      "Epoch 10/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - loss: 898.9813 - rmse: 29.9830 - val_loss: 892.2537 - val_rmse: 29.8706 - learning_rate: 0.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 899.8989 - rmse: 29.9983 - val_loss: 1066.1420 - val_rmse: 32.6518 - learning_rate: 0.0050\n",
      "Epoch 12/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 887.7765 - rmse: 29.7956 - val_loss: 887.4865 - val_rmse: 29.7907 - learning_rate: 0.0050\n",
      "Epoch 13/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 885.9044 - rmse: 29.7641 - val_loss: 896.2809 - val_rmse: 29.9380 - learning_rate: 0.0050\n",
      "Epoch 14/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 870.7873 - rmse: 29.5091 - val_loss: 896.1351 - val_rmse: 29.9355 - learning_rate: 0.0050\n",
      "Epoch 15/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - loss: 866.4787 - rmse: 29.4360 - val_loss: 885.2903 - val_rmse: 29.7538 - learning_rate: 0.0050\n",
      "Epoch 16/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 847.0215 - rmse: 29.1036 - val_loss: 859.8157 - val_rmse: 29.3226 - learning_rate: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - loss: 828.8560 - rmse: 28.7899 - val_loss: 861.1297 - val_rmse: 29.3450 - learning_rate: 0.0050\n",
      "Epoch 18/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 817.4312 - rmse: 28.5908 - val_loss: 861.0536 - val_rmse: 29.3437 - learning_rate: 0.0050\n",
      "Epoch 19/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 811.1301 - rmse: 28.4803 - val_loss: 910.0776 - val_rmse: 30.1675 - learning_rate: 0.0050\n",
      "Epoch 20/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - loss: 776.3370 - rmse: 27.8628 - val_loss: 855.3643 - val_rmse: 29.2466 - learning_rate: 0.0025\n",
      "Epoch 21/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 767.4539 - rmse: 27.7030 - val_loss: 882.0974 - val_rmse: 29.7001 - learning_rate: 0.0025\n",
      "Epoch 22/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 762.5419 - rmse: 27.6142 - val_loss: 866.0720 - val_rmse: 29.4291 - learning_rate: 0.0025\n",
      "Epoch 23/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 759.6696 - rmse: 27.5621 - val_loss: 854.6257 - val_rmse: 29.2340 - learning_rate: 0.0025\n",
      "Epoch 24/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 753.4178 - rmse: 27.4485 - val_loss: 866.6935 - val_rmse: 29.4397 - learning_rate: 0.0025\n",
      "Epoch 25/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - loss: 753.2640 - rmse: 27.4457 - val_loss: 858.0863 - val_rmse: 29.2931 - learning_rate: 0.0025\n",
      "Epoch 26/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - loss: 745.8684 - rmse: 27.3106 - val_loss: 891.2662 - val_rmse: 29.8541 - learning_rate: 0.0025\n",
      "Epoch 27/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 724.6740 - rmse: 26.9198 - val_loss: 866.9536 - val_rmse: 29.4441 - learning_rate: 0.0012\n",
      "Epoch 28/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 720.0946 - rmse: 26.8346 - val_loss: 870.4365 - val_rmse: 29.5032 - learning_rate: 0.0012\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step\n",
      "Best FLOW NN -> RMSE: 28.720, MAE: 20.481, R²: 0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#same portal-flow\n",
    "\n",
    "y_train = df_train[\"FLOW_future_sum\"]\n",
    "y_test = df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "\n",
    "for neurons in number_neurons:\n",
    "    for num_layer in number_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = Sequential()\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "    \n",
    "            hist = model.fit(\n",
    "                X_train_scaled_flow_same, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            this_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, this_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "\n",
    "# Modell with best parameters\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_flow_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "best_model.fit(\n",
    "    X_train_scaled_flow_same, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled_flow_same)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best FLOW NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26e8c8c5-50a9-425d-8f1f-b9b940d4e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\867997906.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse  val_rmse\n",
      "0              16             2          0.00    0.805148  0.790606\n",
      "1              16             2          0.05    0.973746  0.811842\n",
      "2              16             2          0.10    0.822249  0.793180\n",
      "3              16             3          0.00    0.733872  0.737610\n",
      "4              16             3          0.05    0.812134  0.754808\n",
      "5              16             3          0.10    0.878491  0.784833\n",
      "6              16             4          0.00    0.777013  0.766441\n",
      "7              16             4          0.05    0.817865  0.782449\n",
      "8              16             4          0.10    0.857271  0.780539\n",
      "9              32             2          0.00    0.718395  0.731156\n",
      "10             32             2          0.05    0.779175  0.755556\n",
      "11             32             2          0.10    0.830919  0.771503\n",
      "12             32             3          0.00    0.753205  0.745721\n",
      "13             32             3          0.05    0.945618  0.791097\n",
      "14             32             3          0.10    0.839426  0.774840\n",
      "15             32             4          0.00    0.817331  0.776057\n",
      "16             32             4          0.05    0.826668  0.770087\n",
      "17             32             4          0.10    0.865351  0.774622\n",
      "18             64             2          0.00    0.726241  0.732919\n",
      "19             64             2          0.05    0.775880  0.740514\n",
      "20             64             2          0.10    0.784956  0.756553\n",
      "21             64             3          0.00    0.869865  0.817201\n",
      "22             64             3          0.05    0.809672  0.757874\n",
      "23             64             3          0.10    0.927092  0.805171\n",
      "24             64             4          0.00    0.888662  0.800578\n",
      "25             64             4          0.05    0.826923  0.755538\n",
      "26             64             4          0.10    1.077974  0.812046\n",
      "27            128             2          0.00    0.775472  0.756554\n",
      "28            128             2          0.05    0.764023  0.731291\n",
      "29            128             2          0.10    0.917648  0.782089\n",
      "30            128             3          0.00    0.744699  0.737121\n",
      "31            128             3          0.05    0.859786  0.754419\n",
      "32            128             3          0.10    0.862830  0.780701\n",
      "33            128             4          0.00    0.793643  0.794060\n",
      "34            128             4          0.05    1.077041  0.858270\n",
      "35            128             4          0.10    0.951876  0.796824\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step\n",
      "Best SPEED NN -> RMSE: 0.805, MAE: 0.419, R²: 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#same portal-speed\n",
    "y_train = df_train[\"SPEED_future_mean\"]\n",
    "y_test = df_test[\"SPEED_future_mean\"]\n",
    "\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "\n",
    "for neurons in number_neurons:\n",
    "    for num_layer in number_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = Sequential()\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "    \n",
    "            hist = model.fit(\n",
    "                X_train_scaled_speed_same, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            this_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, this_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "\n",
    "#model with best parameters\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_speed_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "best_model.fit(\n",
    "    X_train_scaled_speed_same, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# test\n",
    "y_pred = best_model.predict(X_test_scaled_speed_same)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best SPEED NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22653b62-c1f5-490b-9496-87c46238288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\2257366272.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse   val_rmse\n",
      "0              16             2          0.00   24.768108  25.254890\n",
      "1              16             2          0.05   29.870770  26.075983\n",
      "2              16             2          0.10   33.876259  25.873125\n",
      "3              16             3          0.00   23.947803  24.581074\n",
      "4              16             3          0.05   32.065853  28.567739\n",
      "5              16             3          0.10   34.205040  26.713118\n",
      "6              16             4          0.00   24.628374  25.154072\n",
      "7              16             4          0.05   31.729382  27.132214\n",
      "8              16             4          0.10   33.573238  27.741846\n",
      "9              32             2          0.00   23.871603  24.740385\n",
      "10             32             2          0.05   28.478031  25.412991\n",
      "11             32             2          0.10   29.893749  25.724424\n",
      "12             32             3          0.00   23.454884  24.592428\n",
      "13             32             3          0.05   27.005396  24.729988\n",
      "14             32             3          0.10   28.438347  24.731655\n",
      "15             32             4          0.00   24.006987  24.754995\n",
      "16             32             4          0.05   29.598333  25.834652\n",
      "17             32             4          0.10   31.037954  25.666662\n",
      "18             64             2          0.00   23.552530  24.551559\n",
      "19             64             2          0.05   27.162569  25.262213\n",
      "20             64             2          0.10   30.057209  26.172491\n",
      "21             64             3          0.00   23.170532  24.796612\n",
      "22             64             3          0.05   25.607405  24.497496\n",
      "23             64             3          0.10   26.509783  24.817190\n",
      "24             64             4          0.00   23.471045  24.647360\n",
      "25             64             4          0.05   26.190321  24.921551\n",
      "26             64             4          0.10   30.408360  27.010319\n",
      "27            128             2          0.00   23.614721  24.654772\n",
      "28            128             2          0.05   25.052713  24.795582\n",
      "29            128             2          0.10   27.073999  25.192635\n",
      "30            128             3          0.00   23.714266  25.001190\n",
      "31            128             3          0.05   24.348314  24.660208\n",
      "32            128             3          0.10   24.832069  24.943247\n",
      "33            128             4          0.00   23.297321  24.700212\n",
      "34            128             4          0.05   26.094875  25.349012\n",
      "35            128             4          0.10   30.004120  26.820402\n",
      "64 3 0\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step\n",
      "Best FLOW NN -> RMSE: 24.511, MAE: 17.286, R²: 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#neighbour portal-flow\n",
    "y_train = df_train[\"FLOW_future_sum\"]\n",
    "y_test = df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "\n",
    "for neurons in number_neurons:\n",
    "    for num_layer in number_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = Sequential()\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "\n",
    "            hist = model.fit(\n",
    "                X_train_scaled_flow_neighbour, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            this_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, this_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "print(best_neurons, best_layers, best_dropout)\n",
    "\n",
    "# model with best parameters\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_flow_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "best_model.fit(\n",
    "    X_train_scaled_flow_neighbour, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled_flow_neighbour)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best FLOW NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a4e83b5-2ba0-47f7-b459-24e59f4989bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\326426236.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse  val_rmse\n",
      "0              16             2          0.00    0.917047  0.926511\n",
      "1              16             2          0.05    0.908428  0.900218\n",
      "2              16             2          0.10    0.936143  0.904106\n",
      "3              16             3          0.00    0.855502  0.891089\n",
      "4              16             3          0.05    0.913606  0.893798\n",
      "5              16             3          0.10    0.961896  0.917284\n",
      "6              16             4          0.00    0.858055  0.892206\n",
      "7              16             4          0.05    0.901608  0.892986\n",
      "8              16             4          0.10    0.953182  0.898682\n",
      "9              32             2          0.00    0.870039  0.893049\n",
      "10             32             2          0.05    1.013831  0.976710\n",
      "11             32             2          0.10    0.983026  0.973556\n",
      "12             32             3          0.00    0.881280  0.899969\n",
      "13             32             3          0.05    1.059069  0.964000\n",
      "14             32             3          0.10    0.890266  0.887247\n",
      "15             32             4          0.00    0.911515  0.947719\n",
      "16             32             4          0.05    1.002717  0.949513\n",
      "17             32             4          0.10    0.917669  0.901365\n",
      "18             64             2          0.00    0.865058  0.900217\n",
      "19             64             2          0.05    0.901713  0.884898\n",
      "20             64             2          0.10    0.873667  0.883873\n",
      "21             64             3          0.00    1.011136  0.965759\n",
      "22             64             3          0.05    0.973729  0.924550\n",
      "23             64             3          0.10    0.887519  0.887344\n",
      "24             64             4          0.00    0.955478  0.946387\n",
      "25             64             4          0.05    1.154971  1.002804\n",
      "26             64             4          0.10    0.923697  0.901611\n",
      "27            128             2          0.00    0.899512  0.908445\n",
      "28            128             2          0.05    1.017718  0.968171\n",
      "29            128             2          0.10    0.866816  0.877788\n",
      "30            128             3          0.00    1.006634  1.008220\n",
      "31            128             3          0.05    1.068124  1.003751\n",
      "32            128             3          0.10    0.906062  0.895106\n",
      "33            128             4          0.00    1.034620  0.973314\n",
      "34            128             4          0.05    1.148691  0.969545\n",
      "35            128             4          0.10    1.308806  1.123274\n",
      "128 2 0\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step\n",
      "Best SPEED NN -> RMSE: 0.934, MAE: 0.437, R²: 0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#neighbour portal-speed\n",
    "\n",
    "y_train = df_train[\"SPEED_future_mean\"]\n",
    "y_test = df_test[\"SPEED_future_mean\"]\n",
    "\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "\n",
    "for neurons in number_neurons:\n",
    "    for num_layer in number_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = Sequential()\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "    \n",
    "            # Optional: speichern der besten Gewichte\n",
    "            #checkpoint = ModelCheckpoint(\"model/NN_model_speed_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "    \n",
    "            hist = model.fit(\n",
    "                X_train_scaled_speed_neighbour, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            # Ergebnisse speichern\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            it_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "# Übersicht\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "print(best_neurons, best_layers, best_dropout)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_speed_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "# Training\n",
    "best_model.fit(\n",
    "    X_train_scaled_speed_neighbour, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Testbewertung\n",
    "y_pred = best_model.predict(X_test_scaled_speed_neighbour)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best SPEED NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41bb8c-c0c6-4c9c-b240-9daeaac404bc",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b908c02c-d444-49fa-8820-dc973651104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, seq_length=15, horizon=15):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length - horizon + 1):\n",
    "        Xs.append(X[i:i+seq_length])\n",
    "        ys.append(y[i+seq_length:i+seq_length+horizon])\n",
    "    return np.array(Xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "65d84553-3e22-40d2-b77c-50fbab086b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - loss: 28.2451 - rmse: 5.3146 - val_loss: 18.9741 - val_rmse: 4.3559 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - loss: 16.2927 - rmse: 4.0364 - val_loss: 19.0427 - val_rmse: 4.3638 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 16.2124 - rmse: 4.0265 - val_loss: 18.6845 - val_rmse: 4.3226 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 16.0428 - rmse: 4.0053 - val_loss: 18.7960 - val_rmse: 4.3354 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 15.9892 - rmse: 3.9986 - val_loss: 18.8916 - val_rmse: 4.3464 - learning_rate: 5.0000e-04\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_all[flow_features_neighbour_nl].values\n",
    "y = df_all[f'SENSOR_{target_sensor}_FLOW'].values\n",
    "\n",
    "\n",
    "\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length=15, horizon=15)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "# reshape für den Scaler (2D erwartet)\n",
    "X_scaled = X_scaler.fit_transform(X_seq.reshape(-1, X_seq.shape[2])).reshape(X_seq.shape)\n",
    "#y_scaled = y_scaler.fit_transform(y_seq.reshape(-1, 1))\n",
    "X_seq=X_scaled\n",
    "#y_seq=y_scaled\n",
    "\n",
    "\n",
    "n_features = X_seq.shape[2]\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15,n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=False),\n",
    "    Dense(15)  # 15 Output-Werte für 15-Minuten-Vorhersage\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32,callbacks=[early_stop, reduce_lr, checkpoint], validation_split=0.1,verbose=1)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "201fcd02-866e-47db-afec-c7f09e80d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM (FLOW) -> RMSE: 3.931, MAE: 2.884, R2: 0.644\n",
      "LSTM Sum Forecast (FLOW) → RMSE: 35.576, MAE: 22.303, R²: 0.833\n",
      "(14596, 15)\n",
      "(14596,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LSTM (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "y_test_sum = y_test.sum(axis=1)\n",
    "y_pred_sum = y_pred.sum(axis=1)\n",
    "\n",
    "# Metriken berechnen\n",
    "rmse = mean_squared_error(y_test_sum, y_pred_sum, squared=False)\n",
    "mae = mean_absolute_error(y_test_sum, y_pred_sum)\n",
    "r2 = r2_score(y_test_sum, y_pred_sum)\n",
    "\n",
    "print(f\"LSTM Sum Forecast (FLOW) → RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_pred_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8e74cc93-8cee-4d00-a78e-44ecf85427f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 14ms/step - loss: 21.6212 - rmse: 4.6499 - val_loss: 3.1687 - val_rmse: 1.7801 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - loss: 2.2561 - rmse: 1.5020 - val_loss: 3.0645 - val_rmse: 1.7506 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - loss: 1.9048 - rmse: 1.3802 - val_loss: 2.6482 - val_rmse: 1.6273 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - loss: 1.8661 - rmse: 1.3660 - val_loss: 2.8612 - val_rmse: 1.6915 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - loss: 1.8574 - rmse: 1.3629 - val_loss: 2.5974 - val_rmse: 1.6116 - learning_rate: 5.0000e-04\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "LSTM (SPEED) -> RMSE: 2.094, MAE: 1.477, R2: -0.010\n",
      "LSTM Sum Forecast (SPEED) → RMSE: 25.775, MAE: 19.042, R²: -0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_all[speed_features_neighbour_nl].values\n",
    "y = df_all[f'SENSOR_{target_sensor}_SPEED'].values\n",
    "\n",
    "\n",
    "\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length=15, horizon=15)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "# reshape für den Scaler (2D erwartet)\n",
    "X_scaled = X_scaler.fit_transform(X_seq.reshape(-1, X_seq.shape[2])).reshape(X_seq.shape)\n",
    "#y_scaled = y_scaler.fit_transform(y_seq.reshape(-1, 1))\n",
    "X_seq=X_scaled\n",
    "#y_seq=y_scaled\n",
    "\n",
    "\n",
    "n_features = X_seq.shape[2]\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15,n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=False),\n",
    "    Dense(15)  # 15 Output-Werte für 15-Minuten-Vorhersage\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32,callbacks=[early_stop, reduce_lr, checkpoint], validation_split=0.1,verbose=1)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LSTM (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "y_test_sum = y_test.sum(axis=1)\n",
    "y_pred_sum = y_pred.sum(axis=1)\n",
    "\n",
    "# Metriken berechnen\n",
    "rmse = mean_squared_error(y_test_sum, y_pred_sum, squared=False)\n",
    "mae = mean_absolute_error(y_test_sum, y_pred_sum)\n",
    "r2 = r2_score(y_test_sum, y_pred_sum)\n",
    "\n",
    "print(f\"LSTM Sum Forecast (SPEED) → RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0e260886-11e7-4125-970f-5480370c4193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76171, 15)\n",
      "(73006, 15)\n"
     ]
    }
   ],
   "source": [
    "df_all['FLOW_future_sum'] = (\n",
    "    df_all[f'SENSOR_{target_sensor}_FLOW']\n",
    "    .rolling(15, min_periods=15)\n",
    "    .sum()\n",
    "    .shift(-14)  # damit die Summe bei t=07:02 die Werte von 07:02–07:16 enthält\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "df_all['SPEED_future_mean'] = (\n",
    "    df_all[f'SENSOR_{target_sensor}_SPEED']\n",
    "    .rolling(15, min_periods=15)\n",
    "    .mean()\n",
    "    .shift(-14)  # damit die Summe bei t=07:02 die Werte von 07:02–07:16 enthält\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "print(df_all.shape)\n",
    "df_all = df_all[df_all['Datetime'].dt.time <= time(9, 45)]\n",
    "print(df_all.shape)\n",
    "\n",
    "#print(df_lagged_all[\"Datetime\"]dt.time.min(), df_lagged_all[\"Datetime\"].dt.date.max())\n",
    "#df_all.head(20)\n",
    "#print(df_lagged_all.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d4d05661-71a9-4fe3-ad35-62914fe676d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_sum(X, y, seq_length=15, horizon=15):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length - horizon + 1):\n",
    "        Xs.append(X[i:i+seq_length])\n",
    "        # statt array von 15 Werten → Summe\n",
    "        ys.append(y[i+seq_length:i+seq_length+horizon].sum())  \n",
    "    return np.array(Xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "be418ea0-8322-43ef-a06b-352e5362712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "826c8f02-3084-41bc-925f-fd2f7bec56bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.2134 - rmse: 0.4619 - val_loss: 0.2563 - val_rmse: 0.5063 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.1929 - rmse: 0.4392 - val_loss: 0.2326 - val_rmse: 0.4823 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.1865 - rmse: 0.4318 - val_loss: 0.2620 - val_rmse: 0.5119 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - loss: 0.1817 - rmse: 0.4263 - val_loss: 0.2755 - val_rmse: 0.5249 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - loss: 0.1803 - rmse: 0.4246 - val_loss: 0.2622 - val_rmse: 0.5120 - learning_rate: 5.0000e-04\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "LSTM 1 output (FLOW) -> RMSE: 0.541, MAE: 0.328, R2: 0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "\n",
    "\n",
    "X_train = df_train[flow_features_same].values\n",
    "y_train = df_train['FLOW_future_sum'].values\n",
    "X_test = df_test[flow_features_same].values\n",
    "y_test = df_test['FLOW_future_sum'].values\n",
    "\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences_sum(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_sum(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_flow_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1,verbose=1)\n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "rmse = mean_squared_error(y_test_scaled, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "07e154bd-b73e-458d-9e09-649b13c6b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 0.4509 - rmse: 0.6715 - val_loss: 0.3382 - val_rmse: 0.5815 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.4096 - rmse: 0.6400 - val_loss: 0.3145 - val_rmse: 0.5608 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.4014 - rmse: 0.6336 - val_loss: 0.3002 - val_rmse: 0.5479 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.3900 - rmse: 0.6245 - val_loss: 0.2989 - val_rmse: 0.5467 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.3878 - rmse: 0.6228 - val_loss: 0.3048 - val_rmse: 0.5521 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.3868 - rmse: 0.6219 - val_loss: 0.3204 - val_rmse: 0.5661 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.3868 - rmse: 0.6220 - val_loss: 0.3243 - val_rmse: 0.5695 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.3762 - rmse: 0.6133 - val_loss: 0.3066 - val_rmse: 0.5537 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.3720 - rmse: 0.6099 - val_loss: 0.3179 - val_rmse: 0.5638 - learning_rate: 5.0000e-04\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "LSTM 1 output (SPEED) -> RMSE: 282.437, MAE: 281.816, R2: -65380.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "\n",
    "\n",
    "X_train = df_train[speed_features_same].values\n",
    "y_train = df_train['SPEED_future_mean'].values\n",
    "X_test = df_test[speed_features_same].values\n",
    "y_test = df_test['SPEED_future_mean'].values\n",
    "\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences_sum(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_sum(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_speed_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1,verbose=1)\n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_true = y_scaler.inverse_transform(y_test_scaled)\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "cb4ada60-be44-459d-880f-6ce935ca0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM 1 output (SPEED) -> RMSE: 14.835, MAE: 7.751, R2: 0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c7aeb5b2-c985-47cb-9599-d777b013feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1518 - rmse: 0.3896 - val_loss: 0.2617 - val_rmse: 0.5116 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1194 - rmse: 0.3455 - val_loss: 0.2489 - val_rmse: 0.4989 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1129 - rmse: 0.3361 - val_loss: 0.2693 - val_rmse: 0.5190 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1097 - rmse: 0.3313 - val_loss: 0.2553 - val_rmse: 0.5053 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1082 - rmse: 0.3290 - val_loss: 0.2957 - val_rmse: 0.5438 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1018 - rmse: 0.3191 - val_loss: 0.2295 - val_rmse: 0.4790 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0995 - rmse: 0.3154 - val_loss: 0.2269 - val_rmse: 0.4764 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0985 - rmse: 0.3139 - val_loss: 0.2345 - val_rmse: 0.4843 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0968 - rmse: 0.3112 - val_loss: 0.2328 - val_rmse: 0.4825 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0946 - rmse: 0.3076 - val_loss: 0.2372 - val_rmse: 0.4871 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0913 - rmse: 0.3021 - val_loss: 0.2305 - val_rmse: 0.4801 - learning_rate: 2.5000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0898 - rmse: 0.2997 - val_loss: 0.2327 - val_rmse: 0.4824 - learning_rate: 2.5000e-04\n",
      "\u001b[1m1880/1880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
      "LSTM 1 output (FLOW) -> RMSE: 0.436, MAE: 0.278, R2: 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "\n",
    "\n",
    "X_train = df_train[flow_features_neighbour].values\n",
    "y_train = df_train['FLOW_future_sum'].values\n",
    "X_test = df_test[flow_features_neighbour].values\n",
    "y_test = df_test['FLOW_future_sum'].values\n",
    "\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences_sum(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_sum(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_flow_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1,verbose=1)\n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "rmse = mean_squared_error(y_test_scaled, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e6c7786f-df0a-4a68-9132-9eddab1a871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "LSTM 1 output (FLOW) -> RMSE: 0.390, MAE: 0.266, R2: 0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_test_peak= df_test.set_index(\"Datetime\").between_time(\"07:15\", \"08:30\").reset_index()\n",
    "X_test_peak = df_test_peak[flow_features_neighbour].values\n",
    "y_test_peak = df_test_peak['FLOW_future_sum'].values\n",
    "X_test_seq_peak, y_test_seq_peak = create_sequences_sum(X_test_peak, y_test_peak, seq_length=15, horizon=15)\n",
    "\n",
    "X_test_peak_scaled  = X_scaler.transform(X_test_seq_peak.reshape(-1, X_test_seq_peak.shape[2])).reshape(X_test_seq_peak.shape)\n",
    "y_test_peak_scaled  = y_scaler.transform(y_test_seq_peak.reshape(-1, 1))\n",
    "\n",
    "y_pred = model.predict(X_test_peak_scaled)\n",
    "\n",
    "rmse = mean_squared_error(y_test_peak_scaled, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test_peak_scaled, y_pred)\n",
    "r2 = r2_score(y_test_peak_scaled, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2fa1ae4d-83ff-4e3f-bbf6-cb66a1088180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - loss: 53527.5977 - rmse: 231.3603 - val_loss: 34466.0508 - val_rmse: 185.6503 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 22960.2344 - rmse: 151.5264 - val_loss: 12780.8682 - val_rmse: 113.0525 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 7528.6187 - rmse: 86.7676 - val_loss: 3142.8145 - val_rmse: 56.0608 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 1713.0857 - rmse: 41.3894 - val_loss: 586.0494 - val_rmse: 24.2085 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 591.1666 - rmse: 24.3139 - val_loss: 396.7042 - val_rmse: 19.9174 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 534.4307 - rmse: 23.1178 - val_loss: 398.0320 - val_rmse: 19.9507 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 534.3171 - rmse: 23.1153 - val_loss: 397.8893 - val_rmse: 19.9472 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 530.7504 - rmse: 23.0380 - val_loss: 280.7095 - val_rmse: 16.7544 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 270.5986 - rmse: 16.4499 - val_loss: 255.5532 - val_rmse: 15.9860 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 229.1084 - rmse: 15.1363 - val_loss: 234.5235 - val_rmse: 15.3142 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 226.2008 - rmse: 15.0400 - val_loss: 223.6122 - val_rmse: 14.9537 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 224.0086 - rmse: 14.9669 - val_loss: 268.1994 - val_rmse: 16.3768 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 222.2710 - rmse: 14.9088 - val_loss: 218.2872 - val_rmse: 14.7745 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 215.9557 - rmse: 14.6954 - val_loss: 258.6567 - val_rmse: 16.0828 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 213.1611 - rmse: 14.6000 - val_loss: 198.7733 - val_rmse: 14.0987 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - loss: 209.0308 - rmse: 14.4579 - val_loss: 209.6997 - val_rmse: 14.4810 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 207.0172 - rmse: 14.3881 - val_loss: 178.1054 - val_rmse: 13.3456 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 197.6034 - rmse: 14.0571 - val_loss: 204.3597 - val_rmse: 14.2954 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 187.4665 - rmse: 13.6918 - val_loss: 205.3675 - val_rmse: 14.3306 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 179.6135 - rmse: 13.4020 - val_loss: 230.8539 - val_rmse: 15.1939 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 167.1514 - rmse: 12.9287 - val_loss: 213.1403 - val_rmse: 14.5993 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 162.2598 - rmse: 12.7381 - val_loss: 203.7024 - val_rmse: 14.2724 - learning_rate: 5.0000e-04\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "LSTM 1 output (SPEED) -> RMSE: 17.315, MAE: 9.849, R2: 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "\n",
    "\n",
    "X_train = df_train[speed_features_neighbour].values\n",
    "y_train = df_train['SPEED_future_mean'].values\n",
    "X_test = df_test[speed_features_neighbour].values\n",
    "y_test = df_test['SPEED_future_mean'].values\n",
    "\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences_sum(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_sum(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "#y_scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "\n",
    "#y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "#y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "y_train_scaled=y_train_seq\n",
    "y_test_scaled=y_test_seq\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_speed_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1,verbose=1)\n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "#y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "#y_true = y_scaler.inverse_transform(y_test_scaled)\n",
    "y_pred=y_pred_scaled\n",
    "y_true=y_test_scaled\n",
    "\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55224ae1-83ea-497c-b14e-ff9ed40f318b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
