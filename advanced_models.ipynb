{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7768fd51-9f7b-4fd1-89f7-ce9bb3043009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a6217c-7087-4837-8f49-17e63cf13968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.layers import  Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aabf74bb-a1c9-4222-a454-9b31c8d8a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the necessary dataframes\n",
    "\n",
    "#df_lagged_all = pd.read_parquet(\"data/processed/df_lagged_30_all.parquet\")\n",
    "df_lagged_all = pd.read_parquet(\"data/processed/df_lagged_all_v2.parquet\")\n",
    "df_2_full = pd.read_parquet(\"data/processed/df_2_full_v2.parquet\")\n",
    "\n",
    "df_all=pd.read_parquet(\"data/processed/df_all_v2.parquet\")\n",
    "df_all_peak= df_all.set_index(\"Datetime\").between_time(\"07:15\", \"08:30\").reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800c31a-39c9-40dc-ae2a-76cfb88fe05d",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac797839-78ec-4f39-b417-f351d8b13d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "##define target sensor, sensor in same and neighbouring portal\n",
    "target_sensor = 1076\n",
    "same_portal=\"55620\"\n",
    "neighbour_portal = \"56160\"\n",
    "\n",
    "same_portal_sensors = df_2_full[df_2_full['PORTAL_clean'] == same_portal]['DP_ID'].unique()\n",
    "same_sensors = [s for s in same_portal_sensors if s != target_sensor]\n",
    "\n",
    "\n",
    "neighbour_sensors = df_2_full[df_2_full['PORTAL_clean'] == neighbour_portal]['DP_ID'].unique()\n",
    "bothportals_sensors = df_2_full[df_2_full['PORTAL_clean'].isin([neighbour_portal, same_portal])]['DP_ID'].unique()\n",
    "except_target_sensors = [s for s in bothportals_sensors if s != target_sensor]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f5972f6-5842-446d-8b73-a14928be0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlags=15\n",
    "#nlags=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8be1197-b68b-4342-bb05-ac2585afcee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group features into speed vs flow and same portal vs neighbour portal (not lagged)\n",
    "flow_features_same_nl = [\n",
    "    f'SENSOR_{sensor}_FLOW'\n",
    "    for sensor in same_sensors\n",
    "\n",
    "]\n",
    "flow_features_neighbour_nl = [\n",
    "    f'SENSOR_{sensor}_FLOW'\n",
    "    for sensor in neighbour_sensors\n",
    "\n",
    "]\n",
    "speed_features_same_nl = [\n",
    "    f'SENSOR_{sensor}_SPEED'\n",
    "    for sensor in same_sensors\n",
    "]\n",
    "speed_features_neighbour_nl = [\n",
    "    f'SENSOR_{sensor}_SPEED'\n",
    "    for sensor in neighbour_sensors\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c27edb9-8c27-4658-8c63-b99c6a27ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group features into speed vs flow and same portal vs neighbour portal (lagged)\n",
    "flow_features_same = [\n",
    "    f'SENSOR_{sensor}_FLOW_lag_{i+1}'\n",
    "    for sensor in same_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "flow_features_neighbour = [\n",
    "    f'SENSOR_{sensor}_FLOW_lag_{i+1}'\n",
    "    for sensor in neighbour_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "speed_features_same = [\n",
    "    f'SENSOR_{sensor}_SPEED_lag_{i+1}'\n",
    "    for sensor in same_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "speed_features_neighbour = [\n",
    "    f'SENSOR_{sensor}_SPEED_lag_{i+1}'\n",
    "    for sensor in neighbour_sensors\n",
    "    for i in range(nlags)\n",
    "]        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d9c83-9cd0-4199-9499-f26cd2591ba6",
   "metadata": {},
   "source": [
    "Train -Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a65de289-ff0f-4bbc-bca0-7a623f17634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly split data for training and test\n",
    "df_train, df_test = train_test_split(df_lagged_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094f6e5-8717-4767-9c9d-4d1d54ba1df1",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb15998-0cb4-44b3-9f74-96d1f0f055f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/scaler_speed_neighbour.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FLOW same\n",
    "scaler_flow_same = StandardScaler()\n",
    "X_train_scaled_flow_same = scaler_flow_same.fit_transform(df_train[flow_features_same])\n",
    "X_test_scaled_flow_same  = scaler_flow_same.transform(df_test[flow_features_same])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_flow_same.pkl\")\n",
    "\n",
    "# SPEED same\n",
    "scaler_speed_same = StandardScaler()\n",
    "X_train_scaled_speed_same = scaler_speed_same.fit_transform(df_train[speed_features_same])\n",
    "X_test_scaled_speed_same  = scaler_speed_same.transform(df_test[speed_features_same])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_speed_same.pkl\")\n",
    "\n",
    "\n",
    "# FLOW neighbour\n",
    "scaler_flow_neigh = StandardScaler()\n",
    "X_train_scaled_flow_neighbour = scaler_flow_neigh.fit_transform(df_train[flow_features_neighbour])\n",
    "X_test_scaled_flow_neighbour  = scaler_flow_neigh.transform(df_test[flow_features_neighbour])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_flow_neighbour.pkl\")\n",
    "\n",
    "\n",
    "# SPEED neighbour\n",
    "scaler_speed_neighbour = StandardScaler()\n",
    "X_train_scaled_speed_neighbour = scaler_speed_neighbour.fit_transform(df_train[speed_features_neighbour])\n",
    "X_test_scaled_speed_neighbour  = scaler_speed_neighbour.transform(df_test[speed_features_neighbour])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_speed_neighbour.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a00541-0469-42b8-a950-2daae50434df",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3d2dcf2-9cb4-4c17-8a17-4aacbd056be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Linear Regression (FLOW) -> RMSE: 33.543, MAE: 23.809, R2: 0.836\n",
      "Baseline Linear Regression (SPEED) -> RMSE: 0.861, MAE: 0.462, R2: 0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal\n",
    "\n",
    "#flow model\n",
    "model_flow = LinearRegression()\n",
    "model_flow.fit(df_train[flow_features_same], df_train['FLOW_future_sum'])\n",
    "#speed model\n",
    "model_speed = LinearRegression()\n",
    "model_speed.fit(df_train[speed_features_same], df_train['SPEED_future_mean'])\n",
    "\n",
    "\n",
    "# prediciton flow\n",
    "y_pred = model_flow.predict(df_test[flow_features_same])\n",
    "y_test=df_test['FLOW_future_sum']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Linear Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "#rediction speed\n",
    "y_pred = model_speed.predict(df_test[speed_features_same])\n",
    "y_test=df_test['SPEED_future_mean']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Linear Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "369fcdfe-4284-4b49-9dd6-3eb9388b1d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Linear Regression (FLOW) -> RMSE: 28.474, MAE: 19.559, R2: 0.882\n",
      "Baseline Linear Regression (SPEED) -> RMSE: 1.051, MAE: 0.513, R2: 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal\n",
    "#flow model\n",
    "model_flow = LinearRegression()\n",
    "model_flow.fit(df_train[flow_features_neighbour], df_train['FLOW_future_sum'])\n",
    "#speed model\n",
    "model_speed = LinearRegression()\n",
    "model_speed.fit(df_train[speed_features_neighbour], df_train['SPEED_future_mean'])\n",
    "\n",
    "\n",
    "#prediction flow\n",
    "y_pred = model_flow.predict(df_test[flow_features_neighbour])\n",
    "y_test=df_test['FLOW_future_sum']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Linear Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "#prediction speed\n",
    "y_pred = model_speed.predict(df_test[speed_features_neighbour])\n",
    "y_test=df_test['SPEED_future_mean']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Baseline Linear Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1d7de0-5c50-4357-b051-e5aeae37c355",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15c2a55a-86fe-4c42-b719-43075c777f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression (FLOW) -> RMSE: 28.647, MAE: 20.634, R²: 0.880\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.810, MAE: 0.401, R²: 0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal\n",
    "\n",
    "#flow model\n",
    "model_flow = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model_flow.fit(df_train[flow_features_same], df_train['FLOW_future_sum'])\n",
    "#speed model\n",
    "model_speed = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model_speed.fit(df_train[speed_features_same], df_train['SPEED_future_mean'])\n",
    "\n",
    "\n",
    "\n",
    "#prediction flow\n",
    "y_pred = model_flow.predict(df_test[flow_features_same])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "#prediction speed\n",
    "y_pred = model_speed.predict(df_test[speed_features_same])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6420ac2f-841e-431d-aed5-ce0cc6a5f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression (FLOW) -> RMSE: 24.460, MAE: 17.192, R²: 0.913\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.936, MAE: 0.424, R²: 0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal\n",
    "\n",
    "#flow model\n",
    "model_flow = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model_flow.fit(df_train[flow_features_neighbour], df_train['FLOW_future_sum'])\n",
    "#speed model\n",
    "model_speed = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model_speed.fit(df_train[speed_features_neighbour], df_train['SPEED_future_mean'])\n",
    "\n",
    "\n",
    "\n",
    "#prediction flow\n",
    "y_pred = model_flow.predict(df_test[flow_features_neighbour])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "#prediction speed\n",
    "y_pred = model_speed.predict(df_test[speed_features_neighbour])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2466b25-b0cf-45cb-b70b-70174bae1b91",
   "metadata": {},
   "source": [
    "xgboost with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f1cf3a3b-e25d-425b-bd55-9a52baf9e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters that should be tested\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.001,0.005,0.01, 0.05],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c270770f-9afd-4e21-99a1-bd01467fbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty dataframe for results\n",
    "results_df = pd.DataFrame(columns=[\"Type\", \"MAE\", \"RMSE\", \"R²\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2c63e4f9-e64a-4537-955f-3049a609bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for adding results\n",
    "def add_result(results_df, type, y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "\n",
    "    new_row = {\n",
    "        \"Type\": type,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R²\": r2\n",
    "    }\n",
    "\n",
    "    return pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b359e1cf-6971-4402-8351-98cabfaa939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Beste Parameter (FLOW): {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "XGBoost Regression (FLOW) -> RMSE: 28.311, MAE: 20.292, R²: 0.883\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\1773143569.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter (FLOW): {'subsample': 0.6, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.812, MAE: 0.401, R²: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal\n",
    "#random search flow\n",
    "random_search_flow = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30, \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "random_search_flow.fit(df_train[flow_features_same], df_train[\"FLOW_future_sum\"])\n",
    "#extract best parameters\n",
    "print(\"Beste Parameter (FLOW):\", random_search_flow.best_params_)\n",
    "model_flow = random_search_flow.best_estimator_\n",
    "#save best model\n",
    "model_flow.save_model(\"model/xgb_flow_same.json\")\n",
    "#save features (because in evaluation they have to be put in in same order)\n",
    "features_used = df_train[flow_features_same].columns.tolist()\n",
    "joblib.dump(features_used, \"model/features_flow_same.pkl\")\n",
    "#predection flow\n",
    "y_pred = model_flow.predict(df_test[flow_features_same])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#add results to dataframe\n",
    "results_df = add_result(results_df, \"FLOW -same portal\", y_test, y_pred)\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "#random search speed\n",
    "random_search_speed = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "random_search_speed.fit(df_train[speed_features_same], df_train[\"SPEED_future_mean\"])\n",
    "#extract best parameters\n",
    "print(\"Beste Parameter (SPEED):\", random_search_speed.best_params_)\n",
    "#save best model\n",
    "model_speed = random_search_speed.best_estimator_\n",
    "model_speed.save_model(\"model/xgb_speed_same.json\")\n",
    "#save features (to reuse them in same order on evaluation set)\n",
    "features_used = df_train[speed_features_same].columns.tolist()\n",
    "joblib.dump(features_used, \"model/features_speed_same.pkl\")\n",
    "\n",
    "#prediction speed\n",
    "y_pred = model_speed.predict(df_test[speed_features_same])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#add results to table\n",
    "results_df = add_result(results_df, \"SPEED -same portal\", y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8c16d6f1-4dd1-4fac-a0d5-19846c3a7caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Beste Parameter (FLOW): {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (FLOW) -> RMSE: 24.096, MAE: 16.871, R²: 0.915\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter (FLOW): {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.930, MAE: 0.420, R²: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal\n",
    "#flow random search\n",
    "random_search_flow = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "random_search_flow.fit(df_train[flow_features_neighbour], df_train[\"FLOW_future_sum\"])\n",
    "#save best model\n",
    "print(\"Beste Parameter (FLOW):\", random_search_flow.best_params_)\n",
    "model_flow = random_search_flow.best_estimator_\n",
    "model_flow.save_model(\"model/xgb_flow_neighbour.json\")\n",
    "#save features (to be able to reuse in same order on evaluation set)\n",
    "features_used = df_train[flow_features_neighbour].columns.tolist()\n",
    "joblib.dump(features_used, \"model/features_flow_neighbour.pkl\")\n",
    "\n",
    "#prediction flwo\n",
    "y_pred = model_flow.predict(df_test[flow_features_neighbour])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#add results to dataframe\n",
    "results_df = add_result(results_df, \"FLOW -neighbour portal\", y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "#speed random search\n",
    "random_search_speed = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30, \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "\n",
    "random_search_speed.fit(df_train[speed_features_neighbour], df_train[\"SPEED_future_mean\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_speed.best_params_)\n",
    "#save best model\n",
    "model_speed = random_search_speed.best_estimator_\n",
    "model_speed.save_model(\"model/xgb_speed_neighbour.json\")\n",
    "#save features order\n",
    "features_used = df_train[speed_features_neighbour].columns.tolist()\n",
    "joblib.dump(features_used, \"model/features_speed_neighbour.pkl\")\n",
    "\n",
    "#prediction speed\n",
    "y_pred = model_speed.predict(df_test[speed_features_neighbour])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#add to dataframe\n",
    "results_df = add_result(results_df, \"SPEED -neighbour portal\", y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "66aaf3cf-e402-4db6-a26a-1b91144357f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FLOW -neighbour portal</td>\n",
       "      <td>16.871492</td>\n",
       "      <td>24.095540</td>\n",
       "      <td>0.915146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FLOW -same portal</td>\n",
       "      <td>20.291550</td>\n",
       "      <td>28.310582</td>\n",
       "      <td>0.882863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPEED -neighbour portal</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.930045</td>\n",
       "      <td>0.659704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPEED -same portal</td>\n",
       "      <td>0.401327</td>\n",
       "      <td>0.812237</td>\n",
       "      <td>0.740454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Type        MAE       RMSE        R²\n",
       "2   FLOW -neighbour portal  16.871492  24.095540  0.915146\n",
       "0        FLOW -same portal  20.291550  28.310582  0.882863\n",
       "3  SPEED -neighbour portal   0.419800   0.930045  0.659704\n",
       "1       SPEED -same portal   0.401327   0.812237  0.740454"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f597a15-b86d-4f1f-9416-95e166f15ad4",
   "metadata": {},
   "source": [
    "Feedforward Neural Network (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "14177efa-8919-49c5-9c1c-5b69343236dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast forward NN (FLOW) -> RMSE: 29.248, MAE: 20.778, R²: 0.875\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Fast forward NN (SPEED) -> RMSE: 0.819, MAE: 0.433, R²: 0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal\n",
    "#flow mdoel\n",
    "model_flow= Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled_flow_same.shape[1],)),  \n",
    "    Dense(32, activation='relu'),                                           \n",
    "    Dense(16, activation='relu'),                                         \n",
    "    Dense(1)                                                              \n",
    "])\n",
    "#compile model with mse as loss and mae as metrics\n",
    "model_flow.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "#train model on training data with 20% for validation\n",
    "history_flow = model_flow.fit(\n",
    "    X_train_scaled_flow_same, df_train[\"FLOW_future_sum\"],\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "#prediction flow\n",
    "y_pred = model_flow.predict(X_test_scaled_flow_same)\n",
    "y_test=df_test[\"FLOW_future_sum\"]\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "#speed model\n",
    "model_speed = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled_speed_same.shape[1],)),  \n",
    "    Dense(32, activation='relu'),                                          \n",
    "    Dense(16, activation='relu'),                                           \n",
    "    Dense(1)                                                                \n",
    "])\n",
    "#compile model with mse as loss and mae as metrics\n",
    "model_speed.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "#train model on training data with 20% validation\n",
    "history_speed = model_speed.fit(\n",
    "    X_train_scaled_speed_same, df_train[\"SPEED_future_mean\"],\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(X_test_scaled_speed_same)\n",
    "y_test=df_test[\"SPEED_future_mean\"]\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ca849db4-1240-4f02-947c-5ea3869862ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Fast forward NN (FLOW) -> RMSE: 24.794, MAE: 17.303, R²: 0.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fast forward NN (SPEED) -> RMSE: 0.969, MAE: 0.458, R²: 0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal\n",
    "#flow model\n",
    "model_flow= Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled_flow_neighbour.shape[1],)),  \n",
    "    Dense(32, activation='relu'),                                           \n",
    "    Dense(16, activation='relu'),                                           \n",
    "    Dense(1)                                                                 \n",
    "])\n",
    "#compile model with mse as loss and mea as metrics\n",
    "model_flow.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "#train model with 20% for validation\n",
    "history_flow = model_flow.fit(\n",
    "    X_train_scaled_flow_neighbour, df_train[\"FLOW_future_sum\"],\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "#prediction flow\n",
    "y_pred = model_flow.predict(X_test_scaled_flow_neighbour)\n",
    "y_test=df_test[\"FLOW_future_sum\"]\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "#model speed\n",
    "model_speed = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled_speed_neighbour.shape[1],)), \n",
    "    Dense(32, activation='relu'),                          \n",
    "    Dense(16, activation='relu'),         \n",
    "    Dense(1)                                                   \n",
    "])\n",
    "#compile using adam optimiser\n",
    "model_speed.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "#train model using 20% for validation\n",
    "history_speed = model_speed.fit(\n",
    "    X_train_scaled_speed_neighbour, df_train[\"SPEED_future_mean\"],\n",
    "    validation_split=0.2,  \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "#prediction speed\n",
    "y_pred = model_speed.predict(X_test_scaled_speed_neighbour)\n",
    "y_test=df_test[\"SPEED_future_mean\"]\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d7b75-0f26-460f-8d14-8cd72a2ea300",
   "metadata": {},
   "source": [
    "NN with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d48647a9-4747-4637-a548-8335a8094185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\308595228.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse   val_rmse\n",
      "0              16             2          0.00   29.371403  29.733335\n",
      "1              16             2          0.05   37.075043  33.153324\n",
      "2              16             2          0.10   42.041279  33.635246\n",
      "3              16             3          0.00   27.912714  28.976200\n",
      "4              16             3          0.05   39.897415  33.503639\n",
      "5              16             3          0.10   43.846443  34.295017\n",
      "6              16             4          0.00   28.486589  29.510708\n",
      "7              16             4          0.05   36.866894  31.401754\n",
      "8              16             4          0.10   40.082947  31.197016\n",
      "9              32             2          0.00   28.014595  29.070684\n",
      "10             32             2          0.05   32.399998  30.271238\n",
      "11             32             2          0.10   34.075420  30.764746\n",
      "12             32             3          0.00   27.727701  29.272102\n",
      "13             32             3          0.05   32.647373  30.021769\n",
      "14             32             3          0.10   35.011250  31.629435\n",
      "15             32             4          0.00   28.093256  29.142313\n",
      "16             32             4          0.05   31.315088  29.387403\n",
      "17             32             4          0.10   35.715744  31.192465\n",
      "18             64             2          0.00   27.472795  29.341480\n",
      "19             64             2          0.05   32.532330  30.811172\n",
      "20             64             2          0.10   33.490093  30.293657\n",
      "21             64             3          0.00   28.851919  29.869560\n",
      "22             64             3          0.05   30.222097  29.404978\n",
      "23             64             3          0.10   31.837008  29.717525\n",
      "24             64             4          0.00   27.025183  28.974485\n",
      "25             64             4          0.05   30.128540  29.311167\n",
      "26             64             4          0.10   32.301857  29.614431\n",
      "27            128             2          0.00   27.893883  29.641785\n",
      "28            128             2          0.05   30.282890  29.778042\n",
      "29            128             2          0.10   31.468235  30.192453\n",
      "30            128             3          0.00   27.376104  29.253227\n",
      "31            128             3          0.05   28.109545  28.893290\n",
      "32            128             3          0.10   28.693462  29.138802\n",
      "33            128             4          0.00   28.150019  29.234877\n",
      "34            128             4          0.05   29.346590  29.468685\n",
      "35            128             4          0.10   30.588945  29.653276\n",
      "Epoch 1/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 891us/step - loss: 1731.5171 - rmse: 41.6115 - val_loss: 1050.1238 - val_rmse: 32.4056 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - loss: 1095.2737 - rmse: 33.0949 - val_loss: 1041.9083 - val_rmse: 32.2786 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - loss: 1052.7274 - rmse: 32.4458 - val_loss: 964.5223 - val_rmse: 31.0568 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - loss: 1027.7020 - rmse: 32.0578 - val_loss: 976.1412 - val_rmse: 31.2433 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 994.6746 - rmse: 31.5385 - val_loss: 1033.4736 - val_rmse: 32.1477 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - loss: 981.7228 - rmse: 31.3325 - val_loss: 985.1785 - val_rmse: 31.3876 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 914.6654 - rmse: 30.2434 - val_loss: 898.3356 - val_rmse: 29.9722 - learning_rate: 0.0050\n",
      "Epoch 8/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 913.1998 - rmse: 30.2192 - val_loss: 908.3728 - val_rmse: 30.1392 - learning_rate: 0.0050\n",
      "Epoch 9/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - loss: 905.7272 - rmse: 30.0953 - val_loss: 921.6393 - val_rmse: 30.3585 - learning_rate: 0.0050\n",
      "Epoch 10/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - loss: 898.9813 - rmse: 29.9830 - val_loss: 892.2537 - val_rmse: 29.8706 - learning_rate: 0.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 899.8989 - rmse: 29.9983 - val_loss: 1066.1420 - val_rmse: 32.6518 - learning_rate: 0.0050\n",
      "Epoch 12/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 887.7765 - rmse: 29.7956 - val_loss: 887.4865 - val_rmse: 29.7907 - learning_rate: 0.0050\n",
      "Epoch 13/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 885.9044 - rmse: 29.7641 - val_loss: 896.2809 - val_rmse: 29.9380 - learning_rate: 0.0050\n",
      "Epoch 14/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 870.7873 - rmse: 29.5091 - val_loss: 896.1351 - val_rmse: 29.9355 - learning_rate: 0.0050\n",
      "Epoch 15/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - loss: 866.4787 - rmse: 29.4360 - val_loss: 885.2903 - val_rmse: 29.7538 - learning_rate: 0.0050\n",
      "Epoch 16/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 847.0215 - rmse: 29.1036 - val_loss: 859.8157 - val_rmse: 29.3226 - learning_rate: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - loss: 828.8560 - rmse: 28.7899 - val_loss: 861.1297 - val_rmse: 29.3450 - learning_rate: 0.0050\n",
      "Epoch 18/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 817.4312 - rmse: 28.5908 - val_loss: 861.0536 - val_rmse: 29.3437 - learning_rate: 0.0050\n",
      "Epoch 19/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 811.1301 - rmse: 28.4803 - val_loss: 910.0776 - val_rmse: 30.1675 - learning_rate: 0.0050\n",
      "Epoch 20/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - loss: 776.3370 - rmse: 27.8628 - val_loss: 855.3643 - val_rmse: 29.2466 - learning_rate: 0.0025\n",
      "Epoch 21/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 767.4539 - rmse: 27.7030 - val_loss: 882.0974 - val_rmse: 29.7001 - learning_rate: 0.0025\n",
      "Epoch 22/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 762.5419 - rmse: 27.6142 - val_loss: 866.0720 - val_rmse: 29.4291 - learning_rate: 0.0025\n",
      "Epoch 23/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 759.6696 - rmse: 27.5621 - val_loss: 854.6257 - val_rmse: 29.2340 - learning_rate: 0.0025\n",
      "Epoch 24/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 753.4178 - rmse: 27.4485 - val_loss: 866.6935 - val_rmse: 29.4397 - learning_rate: 0.0025\n",
      "Epoch 25/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - loss: 753.2640 - rmse: 27.4457 - val_loss: 858.0863 - val_rmse: 29.2931 - learning_rate: 0.0025\n",
      "Epoch 26/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - loss: 745.8684 - rmse: 27.3106 - val_loss: 891.2662 - val_rmse: 29.8541 - learning_rate: 0.0025\n",
      "Epoch 27/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 724.6740 - rmse: 26.9198 - val_loss: 866.9536 - val_rmse: 29.4441 - learning_rate: 0.0012\n",
      "Epoch 28/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 720.0946 - rmse: 26.8346 - val_loss: 870.4365 - val_rmse: 29.5032 - learning_rate: 0.0012\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step\n",
      "Best FLOW NN -> RMSE: 28.720, MAE: 20.481, R²: 0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal -flow\n",
    "\n",
    "y_train = df_train[\"FLOW_future_sum\"]\n",
    "y_test = df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "#different parameters that will be tried during gridsearch\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "#dataframe for results\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "#self-made gridsearch\n",
    "#loop over number neurons\n",
    "for neurons in number_neurons:\n",
    "    #loop over number of layers\n",
    "    for num_layer in number_layers:\n",
    "        #loop over drop out rate\n",
    "        for dropout_rate in dropout_rates:\n",
    "            #built model\n",
    "            model = Sequential()\n",
    "            #loop over number of layers\n",
    "            for _ in range(num_layer):\n",
    "                #construct model\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            #finalise model\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "            #early stop to avoid overfitting to training data\n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "            #train model\n",
    "            hist = model.fit(\n",
    "                X_train_scaled_flow_same, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "            #calculate metrics and add to table\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            this_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, this_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "#print all combinations\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "#find best set of parameters\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "\n",
    "# retrain model with best parameters\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_flow_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "best_model.fit(\n",
    "    X_train_scaled_flow_same, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "#prediction with best model\n",
    "y_pred = best_model.predict(X_test_scaled_flow_same)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best FLOW NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26e8c8c5-50a9-425d-8f1f-b9b940d4e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\867997906.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse  val_rmse\n",
      "0              16             2          0.00    0.805148  0.790606\n",
      "1              16             2          0.05    0.973746  0.811842\n",
      "2              16             2          0.10    0.822249  0.793180\n",
      "3              16             3          0.00    0.733872  0.737610\n",
      "4              16             3          0.05    0.812134  0.754808\n",
      "5              16             3          0.10    0.878491  0.784833\n",
      "6              16             4          0.00    0.777013  0.766441\n",
      "7              16             4          0.05    0.817865  0.782449\n",
      "8              16             4          0.10    0.857271  0.780539\n",
      "9              32             2          0.00    0.718395  0.731156\n",
      "10             32             2          0.05    0.779175  0.755556\n",
      "11             32             2          0.10    0.830919  0.771503\n",
      "12             32             3          0.00    0.753205  0.745721\n",
      "13             32             3          0.05    0.945618  0.791097\n",
      "14             32             3          0.10    0.839426  0.774840\n",
      "15             32             4          0.00    0.817331  0.776057\n",
      "16             32             4          0.05    0.826668  0.770087\n",
      "17             32             4          0.10    0.865351  0.774622\n",
      "18             64             2          0.00    0.726241  0.732919\n",
      "19             64             2          0.05    0.775880  0.740514\n",
      "20             64             2          0.10    0.784956  0.756553\n",
      "21             64             3          0.00    0.869865  0.817201\n",
      "22             64             3          0.05    0.809672  0.757874\n",
      "23             64             3          0.10    0.927092  0.805171\n",
      "24             64             4          0.00    0.888662  0.800578\n",
      "25             64             4          0.05    0.826923  0.755538\n",
      "26             64             4          0.10    1.077974  0.812046\n",
      "27            128             2          0.00    0.775472  0.756554\n",
      "28            128             2          0.05    0.764023  0.731291\n",
      "29            128             2          0.10    0.917648  0.782089\n",
      "30            128             3          0.00    0.744699  0.737121\n",
      "31            128             3          0.05    0.859786  0.754419\n",
      "32            128             3          0.10    0.862830  0.780701\n",
      "33            128             4          0.00    0.793643  0.794060\n",
      "34            128             4          0.05    1.077041  0.858270\n",
      "35            128             4          0.10    0.951876  0.796824\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step\n",
      "Best SPEED NN -> RMSE: 0.805, MAE: 0.419, R²: 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal -speed\n",
    "y_train = df_train[\"SPEED_future_mean\"]\n",
    "y_test = df_test[\"SPEED_future_mean\"]\n",
    "\n",
    "#different parameters that will be tried during gridsearch\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "#dataframe for gridsearch results\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "#manual gridsearch\n",
    "#loop over number of neurons\n",
    "for neurons in number_neurons:\n",
    "    #loop over number of layers\n",
    "    for num_layer in number_layers:\n",
    "        #loop over different dropoutrates\n",
    "        for dropout_rate in dropout_rates:\n",
    "            #start building model\n",
    "            model = Sequential()\n",
    "            #loop over the number of layers\n",
    "            for _ in range(num_layer):\n",
    "                #continue building model\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            #finalise model\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "            #early stop to prevent overfitting\n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "            #training of model with 20% validation\n",
    "            hist = model.fit(\n",
    "                X_train_scaled_speed_same, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "            #extract metrics and add to dataframe\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            this_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, this_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "#print dtaframe with all results\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "#extract best parameters\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "\n",
    "#retrain model with best parameters\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_speed_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "best_model.fit(\n",
    "    X_train_scaled_speed_same, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# prediction speed with best model\n",
    "y_pred = best_model.predict(X_test_scaled_speed_same)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best SPEED NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22653b62-c1f5-490b-9496-87c46238288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\2257366272.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse   val_rmse\n",
      "0              16             2          0.00   24.768108  25.254890\n",
      "1              16             2          0.05   29.870770  26.075983\n",
      "2              16             2          0.10   33.876259  25.873125\n",
      "3              16             3          0.00   23.947803  24.581074\n",
      "4              16             3          0.05   32.065853  28.567739\n",
      "5              16             3          0.10   34.205040  26.713118\n",
      "6              16             4          0.00   24.628374  25.154072\n",
      "7              16             4          0.05   31.729382  27.132214\n",
      "8              16             4          0.10   33.573238  27.741846\n",
      "9              32             2          0.00   23.871603  24.740385\n",
      "10             32             2          0.05   28.478031  25.412991\n",
      "11             32             2          0.10   29.893749  25.724424\n",
      "12             32             3          0.00   23.454884  24.592428\n",
      "13             32             3          0.05   27.005396  24.729988\n",
      "14             32             3          0.10   28.438347  24.731655\n",
      "15             32             4          0.00   24.006987  24.754995\n",
      "16             32             4          0.05   29.598333  25.834652\n",
      "17             32             4          0.10   31.037954  25.666662\n",
      "18             64             2          0.00   23.552530  24.551559\n",
      "19             64             2          0.05   27.162569  25.262213\n",
      "20             64             2          0.10   30.057209  26.172491\n",
      "21             64             3          0.00   23.170532  24.796612\n",
      "22             64             3          0.05   25.607405  24.497496\n",
      "23             64             3          0.10   26.509783  24.817190\n",
      "24             64             4          0.00   23.471045  24.647360\n",
      "25             64             4          0.05   26.190321  24.921551\n",
      "26             64             4          0.10   30.408360  27.010319\n",
      "27            128             2          0.00   23.614721  24.654772\n",
      "28            128             2          0.05   25.052713  24.795582\n",
      "29            128             2          0.10   27.073999  25.192635\n",
      "30            128             3          0.00   23.714266  25.001190\n",
      "31            128             3          0.05   24.348314  24.660208\n",
      "32            128             3          0.10   24.832069  24.943247\n",
      "33            128             4          0.00   23.297321  24.700212\n",
      "34            128             4          0.05   26.094875  25.349012\n",
      "35            128             4          0.10   30.004120  26.820402\n",
      "64 3 0\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step\n",
      "Best FLOW NN -> RMSE: 24.511, MAE: 17.286, R²: 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal -flow\n",
    "y_train = df_train[\"FLOW_future_sum\"]\n",
    "y_test = df_test[\"FLOW_future_sum\"]\n",
    "#parameters that are addapted in gridsearch\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "#prepare dataframe for gridsearch\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "#manual gridsearch\n",
    "#loop over the number of neurons\n",
    "for neurons in number_neurons:\n",
    "    #loop over number of layers\n",
    "    for num_layer in number_layers:\n",
    "        #loop over drop out rates\n",
    "        for dropout_rate in dropout_rates:\n",
    "            #start building model\n",
    "            model = Sequential()\n",
    "            #add the number of layers defined\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            #finalise model construction\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "            #add early stop to prevent overfitting\n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "            #fit model\n",
    "            hist = model.fit(\n",
    "                X_train_scaled_flow_neighbour, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "            #extract metrics and put in dataframe\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            this_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, this_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "#print whole dataframe\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "print(best_neurons, best_layers, best_dropout)\n",
    "\n",
    "# retrain model with best parameters\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_flow_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "best_model.fit(\n",
    "    X_train_scaled_flow_neighbour, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "#prediction on testset\n",
    "y_pred = best_model.predict(X_test_scaled_flow_neighbour)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best FLOW NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a4e83b5-2ba0-47f7-b459-24e59f4989bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\326426236.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse  val_rmse\n",
      "0              16             2          0.00    0.917047  0.926511\n",
      "1              16             2          0.05    0.908428  0.900218\n",
      "2              16             2          0.10    0.936143  0.904106\n",
      "3              16             3          0.00    0.855502  0.891089\n",
      "4              16             3          0.05    0.913606  0.893798\n",
      "5              16             3          0.10    0.961896  0.917284\n",
      "6              16             4          0.00    0.858055  0.892206\n",
      "7              16             4          0.05    0.901608  0.892986\n",
      "8              16             4          0.10    0.953182  0.898682\n",
      "9              32             2          0.00    0.870039  0.893049\n",
      "10             32             2          0.05    1.013831  0.976710\n",
      "11             32             2          0.10    0.983026  0.973556\n",
      "12             32             3          0.00    0.881280  0.899969\n",
      "13             32             3          0.05    1.059069  0.964000\n",
      "14             32             3          0.10    0.890266  0.887247\n",
      "15             32             4          0.00    0.911515  0.947719\n",
      "16             32             4          0.05    1.002717  0.949513\n",
      "17             32             4          0.10    0.917669  0.901365\n",
      "18             64             2          0.00    0.865058  0.900217\n",
      "19             64             2          0.05    0.901713  0.884898\n",
      "20             64             2          0.10    0.873667  0.883873\n",
      "21             64             3          0.00    1.011136  0.965759\n",
      "22             64             3          0.05    0.973729  0.924550\n",
      "23             64             3          0.10    0.887519  0.887344\n",
      "24             64             4          0.00    0.955478  0.946387\n",
      "25             64             4          0.05    1.154971  1.002804\n",
      "26             64             4          0.10    0.923697  0.901611\n",
      "27            128             2          0.00    0.899512  0.908445\n",
      "28            128             2          0.05    1.017718  0.968171\n",
      "29            128             2          0.10    0.866816  0.877788\n",
      "30            128             3          0.00    1.006634  1.008220\n",
      "31            128             3          0.05    1.068124  1.003751\n",
      "32            128             3          0.10    0.906062  0.895106\n",
      "33            128             4          0.00    1.034620  0.973314\n",
      "34            128             4          0.05    1.148691  0.969545\n",
      "35            128             4          0.10    1.308806  1.123274\n",
      "128 2 0\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step\n",
      "Best SPEED NN -> RMSE: 0.934, MAE: 0.437, R²: 0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal -speed\n",
    "\n",
    "y_train = df_train[\"SPEED_future_mean\"]\n",
    "y_test = df_test[\"SPEED_future_mean\"]\n",
    "#values for gridsearch\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "#prerpare dataframe for gridserach\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "#,manual gridsearch\n",
    "#manual gridsearch\n",
    "#loop over number of neurons\n",
    "for neurons in number_neurons:\n",
    "    #loop over number of laers\n",
    "    for num_layer in number_layers:\n",
    "        #loop over different dropoutrates\n",
    "        for dropout_rate in dropout_rates:\n",
    "            #start constructi g model\n",
    "            model = Sequential()\n",
    "            #add the number of layers specified\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            #finalise model\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "            #earily stop to prevent overfittng\n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "    \n",
    "            #train model with 20% validation\n",
    "            hist = model.fit(\n",
    "                X_train_scaled_speed_neighbour, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            # save metrics in dataframe\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            it_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "# print whole dataframe\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "#extract best set of parameters\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "print(best_neurons, best_layers, best_dropout)\n",
    "\n",
    "# retrain best model\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_speed_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "best_model.fit(\n",
    "    X_train_scaled_speed_neighbour, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# prediction on testset\n",
    "y_pred = best_model.predict(X_test_scaled_speed_neighbour)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best SPEED NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41bb8c-c0c6-4c9c-b240-9daeaac404bc",
   "metadata": {},
   "source": [
    "LSTM -15 output features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b908c02c-d444-49fa-8820-dc973651104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create sequences as needed by lstm model with 15 input and 15 output features\n",
    "def create_sequences(X, y, seq_length=15, horizon=15):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length - horizon + 1):\n",
    "        Xs.append(X[i:i+seq_length])\n",
    "        ys.append(y[i+seq_length:i+seq_length+horizon])\n",
    "    return np.array(Xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e74cc93-8cee-4d00-a78e-44ecf85427f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - loss: 31.8710 - rmse: 5.6454 - val_loss: 19.3437 - val_rmse: 4.3981 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 17.1737 - rmse: 4.1441 - val_loss: 19.2898 - val_rmse: 4.3920 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 17.0409 - rmse: 4.1281 - val_loss: 19.3172 - val_rmse: 4.3951 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 16.9772 - rmse: 4.1203 - val_loss: 19.2657 - val_rmse: 4.3893 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 16.9141 - rmse: 4.1127 - val_loss: 19.7873 - val_rmse: 4.4483 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 16.8586 - rmse: 4.1059 - val_loss: 19.7478 - val_rmse: 4.4438 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - loss: 16.8400 - rmse: 4.1037 - val_loss: 19.3283 - val_rmse: 4.3964 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 16.7092 - rmse: 4.0877 - val_loss: 19.3733 - val_rmse: 4.4015 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 16.6498 - rmse: 4.0804 - val_loss: 19.7899 - val_rmse: 4.4486 - learning_rate: 5.0000e-04\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "LSTM (FLOW) -> RMSE: 4.171, MAE: 3.083, R2: 0.601\n",
      "LSTM Sum Forecast (FLOW) → RMSE: 40.725, MAE: 25.909, R²: 0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal-flow\n",
    "\n",
    "X = df_all[flow_features_same_nl].values\n",
    "y = df_all[f'SENSOR_{target_sensor}_FLOW'].values\n",
    "#create sequences\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length=15, horizon=15)\n",
    "X_scaler = StandardScaler()\n",
    "#scale values\n",
    "X_scaled = X_scaler.fit_transform(X_seq.reshape(-1, X_seq.shape[2])).reshape(X_seq.shape)\n",
    "X_seq=X_scaled\n",
    "\n",
    "n_features = X_seq.shape[2]\n",
    "#create model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15,n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=False),\n",
    "    Dense(15)  \n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#split test-training data\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "#fit model\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_flow_same_15output.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32,callbacks=[early_stop, reduce_lr, checkpoint], validation_split=0.2,verbose=1)\n",
    "\n",
    "#predict 15 output values\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LSTM (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "#sum 15 output values for summed flow\n",
    "y_test_sum = y_test.sum(axis=1)\n",
    "y_pred_sum = y_pred.sum(axis=1)\n",
    "#metrics for summed flow\n",
    "rmse = mean_squared_error(y_test_sum, y_pred_sum, squared=False)\n",
    "mae = mean_absolute_error(y_test_sum, y_pred_sum)\n",
    "r2 = r2_score(y_test_sum, y_pred_sum)\n",
    "\n",
    "print(f\"LSTM Sum Forecast (FLOW) → RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7e7b54d-e07d-4dd0-8d50-f9e1eb8b385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 14ms/step - loss: 22.1927 - rmse: 4.7109 - val_loss: 2.9518 - val_rmse: 1.7181 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 2.4795 - rmse: 1.5747 - val_loss: 1.6654 - val_rmse: 1.2905 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.7792 - rmse: 1.3339 - val_loss: 1.6525 - val_rmse: 1.2855 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.7465 - rmse: 1.3215 - val_loss: 1.6705 - val_rmse: 1.2925 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.7276 - rmse: 1.3144 - val_loss: 1.6751 - val_rmse: 1.2943 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.7194 - rmse: 1.3112 - val_loss: 1.6628 - val_rmse: 1.2895 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.6870 - rmse: 1.2989 - val_loss: 1.6313 - val_rmse: 1.2772 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.6818 - rmse: 1.2968 - val_loss: 1.6703 - val_rmse: 1.2924 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.6755 - rmse: 1.2944 - val_loss: 1.6655 - val_rmse: 1.2905 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 1.6690 - rmse: 1.2919 - val_loss: 1.6619 - val_rmse: 1.2892 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 1.6575 - rmse: 1.2874 - val_loss: 1.6517 - val_rmse: 1.2852 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.6556 - rmse: 1.2867 - val_loss: 1.6541 - val_rmse: 1.2861 - learning_rate: 2.5000e-04\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step\n",
      "LSTM (SPEED) -> RMSE: 1.460, MAE: 0.987, R2: 0.496\n",
      "LSTM Mean Forecast (SPEED) → RMSE: 0.880, MAE: 0.511, R²: 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal-speed\n",
    "\n",
    "X = df_all[speed_features_same_nl].values\n",
    "y = df_all[f'SENSOR_{target_sensor}_SPEED'].values\n",
    "\n",
    "\n",
    "#create sequences\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length=15, horizon=15)\n",
    "#scale\n",
    "X_scaler = StandardScaler()\n",
    "X_scaled = X_scaler.fit_transform(X_seq.reshape(-1, X_seq.shape[2])).reshape(X_seq.shape)\n",
    "X_seq=X_scaled\n",
    "\n",
    "n_features = X_seq.shape[2]\n",
    "#create model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15,n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=False),\n",
    "    Dense(15)  \n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#make train-test-split\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "#train model and save it, early stop to avoid overfitting\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_speed_same_15output.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32,callbacks=[early_stop, reduce_lr, checkpoint], validation_split=0.2,verbose=1)\n",
    "\n",
    "#predict 15 output values\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LSTM (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "#take mean for average speed\n",
    "y_test_mean = y_test.mean(axis=1)\n",
    "y_pred_mean = y_pred.mean(axis=1)\n",
    "\n",
    "#metrics for average speed\n",
    "rmse = mean_squared_error(y_test_mean, y_pred_mean, squared=False)\n",
    "mae = mean_absolute_error(y_test_mean, y_pred_mean)\n",
    "r2 = r2_score(y_test_mean, y_pred_mean)\n",
    "\n",
    "print(f\"LSTM Mean Forecast (SPEED) → RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65d84553-3e22-40d2-b77c-50fbab086b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 14ms/step - loss: 31.2194 - rmse: 5.5874 - val_loss: 18.1018 - val_rmse: 4.2546 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 16.2833 - rmse: 4.0353 - val_loss: 18.0064 - val_rmse: 4.2434 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 16.2089 - rmse: 4.0260 - val_loss: 18.1152 - val_rmse: 4.2562 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 16.1241 - rmse: 4.0155 - val_loss: 17.9899 - val_rmse: 4.2415 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 16.0133 - rmse: 4.0017 - val_loss: 18.1974 - val_rmse: 4.2658 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 15.9766 - rmse: 3.9971 - val_loss: 18.0240 - val_rmse: 4.2455 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 15.8635 - rmse: 3.9829 - val_loss: 18.1020 - val_rmse: 4.2546 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 15.7428 - rmse: 3.9677 - val_loss: 18.1508 - val_rmse: 4.2604 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - loss: 15.6971 - rmse: 3.9620 - val_loss: 18.1418 - val_rmse: 4.2593 - learning_rate: 5.0000e-04\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
      "LSTM (FLOW) -> RMSE: 3.918, MAE: 2.910, R2: 0.648\n",
      "LSTM Sum Forecast (FLOW) → RMSE: 34.867, MAE: 22.393, R²: 0.840\n",
      "(15229, 15)\n",
      "(15229,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal-flow\n",
    "\n",
    "X = df_all[flow_features_neighbour_nl].values\n",
    "y = df_all[f'SENSOR_{target_sensor}_FLOW'].values\n",
    "\n",
    "\n",
    "#create sequence\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length=15, horizon=15)\n",
    "X_scaler = StandardScaler()\n",
    "#scale values\n",
    "X_scaled = X_scaler.fit_transform(X_seq.reshape(-1, X_seq.shape[2])).reshape(X_seq.shape)\n",
    "X_seq=X_scaled\n",
    "\n",
    "n_features = X_seq.shape[2]\n",
    "#create model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15,n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=False),\n",
    "    Dense(15)  \n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#split train-test data\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "#train model with early stop and save it\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_flow_neighbour_15output.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32,callbacks=[early_stop, reduce_lr, checkpoint], validation_split=0.2,verbose=1)\n",
    "\n",
    "#predict 15 output values\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LSTM (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "#sum 15 output values for summed flow\n",
    "y_test_sum = y_test.sum(axis=1)\n",
    "y_pred_sum = y_pred.sum(axis=1)\n",
    "\n",
    "# calculate metrics for summed flow\n",
    "rmse = mean_squared_error(y_test_sum, y_pred_sum, squared=False)\n",
    "mae = mean_absolute_error(y_test_sum, y_pred_sum)\n",
    "r2 = r2_score(y_test_sum, y_pred_sum)\n",
    "\n",
    "print(f\"LSTM Sum Forecast (FLOW) → RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_pred_sum.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1122b824-bf49-4816-abea-326b6413eb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - loss: 22.7986 - rmse: 4.7748 - val_loss: 2.9560 - val_rmse: 1.7193 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 2.2857 - rmse: 1.5119 - val_loss: 2.5317 - val_rmse: 1.5911 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 2.0106 - rmse: 1.4179 - val_loss: 2.6996 - val_rmse: 1.6430 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.9894 - rmse: 1.4105 - val_loss: 2.3272 - val_rmse: 1.5255 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.9724 - rmse: 1.4044 - val_loss: 2.5430 - val_rmse: 1.5947 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.9613 - rmse: 1.4005 - val_loss: 2.3968 - val_rmse: 1.5482 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 1.9466 - rmse: 1.3952 - val_loss: 2.3781 - val_rmse: 1.5421 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.9074 - rmse: 1.3811 - val_loss: 2.5545 - val_rmse: 1.5983 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 1.8977 - rmse: 1.3776 - val_loss: 2.2969 - val_rmse: 1.5155 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - loss: 1.8861 - rmse: 1.3734 - val_loss: 2.3595 - val_rmse: 1.5361 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.8649 - rmse: 1.3656 - val_loss: 2.5611 - val_rmse: 1.6003 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.8533 - rmse: 1.3613 - val_loss: 2.4843 - val_rmse: 1.5762 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 1.8191 - rmse: 1.3487 - val_loss: 2.4066 - val_rmse: 1.5513 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 1.8033 - rmse: 1.3429 - val_loss: 2.4839 - val_rmse: 1.5761 - learning_rate: 2.5000e-04\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "LSTM (SPEED) -> RMSE: 1.563, MAE: 1.021, R2: 0.424\n",
      "LSTM Mean Forecast (SPEED) → RMSE: 1.038, MAE: 0.560, R²: 0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal-speed\n",
    "\n",
    "X = df_all[speed_features_neighbour_nl].values\n",
    "y = df_all[f'SENSOR_{target_sensor}_SPEED'].values\n",
    "\n",
    "\n",
    "#create sequences\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length=15, horizon=15)\n",
    "#scale it\n",
    "X_scaler = StandardScaler()\n",
    "X_scaled = X_scaler.fit_transform(X_seq.reshape(-1, X_seq.shape[2])).reshape(X_seq.shape)\n",
    "X_seq=X_scaled\n",
    "\n",
    "n_features = X_seq.shape[2]\n",
    "#create model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15,n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=False),\n",
    "    Dense(15)  \n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#train test split\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "#fit mdoel with early stop to prevent overfitting and save\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_speed_neighbour_15output.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32,callbacks=[early_stop, reduce_lr, checkpoint], validation_split=0.2,verbose=1)\n",
    "\n",
    "#predict 15 output values\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LSTM (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "#take mean of 15 output to get average speed\n",
    "y_test_mean = y_test.mean(axis=1)\n",
    "y_pred_mean = y_pred.mean(axis=1)\n",
    "#compute metrics for mean speed\n",
    "rmse = mean_squared_error(y_test_mean, y_pred_mean, squared=False)\n",
    "mae = mean_absolute_error(y_test_mean, y_pred_mean)\n",
    "r2 = r2_score(y_test_mean, y_pred_mean)\n",
    "\n",
    "print(f\"LSTM Mean Forecast (SPEED) → RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95290d28-578b-4887-ad5f-a7cc4345b4a3",
   "metadata": {},
   "source": [
    "LSTM -directly one output feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e260886-11e7-4125-970f-5480370c4193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73006, 15)\n",
      "(73006, 15)\n"
     ]
    }
   ],
   "source": [
    "#adds the target value (summed flow for upcoming 15 mins)\n",
    "df_all['FLOW_future_sum'] = (\n",
    "    df_all[f'SENSOR_{target_sensor}_FLOW']\n",
    "    .rolling(15, min_periods=15)\n",
    "    .sum()\n",
    "    .shift(-14)  # so that the sum at  t=07:02 is the sum of the values 07:02–07:16 \n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "#adds the target value (mean speed for upcoming 15 mins)\n",
    "df_all['SPEED_future_mean'] = (\n",
    "    df_all[f'SENSOR_{target_sensor}_SPEED']\n",
    "    .rolling(15, min_periods=15)\n",
    "    .mean()\n",
    "    .shift(-14)  # so that the mean at  t=07:02 is the mean of the values 07:02–07:16 \n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "print(df_all.shape)\n",
    "df_all = df_all[df_all['Datetime'].dt.time <= time(9, 45)]\n",
    "print(df_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4d05661-71a9-4fe3-ad35-62914fe676d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_sum(X, y, seq_length=15, horizon=15): #create sequences with target sum flow directly\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length - horizon + 1):\n",
    "        Xs.append(X[i:i+seq_length])\n",
    "        ys.append(y[i+seq_length:i+seq_length+horizon].sum())  \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def create_sequences_mean(X, y, seq_length=15, horizon=15): #create sequences with speedmean as target directly\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length - horizon + 1):\n",
    "        Xs.append(X[i:i+seq_length])\n",
    "        # statt array von 15 Werten → Summe\n",
    "        ys.append(y[i+seq_length:i+seq_length+horizon].mean())  \n",
    "    return np.array(Xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be418ea0-8322-43ef-a06b-352e5362712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stop to prevent overfitting and reduce learning rate\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "826c8f02-3084-41bc-925f-fd2f7bec56bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 0.2134 - rmse: 0.4619 - val_loss: 0.2563 - val_rmse: 0.5063 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.1929 - rmse: 0.4392 - val_loss: 0.2326 - val_rmse: 0.4823 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.1865 - rmse: 0.4318 - val_loss: 0.2620 - val_rmse: 0.5119 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - loss: 0.1817 - rmse: 0.4263 - val_loss: 0.2755 - val_rmse: 0.5249 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - loss: 0.1803 - rmse: 0.4246 - val_loss: 0.2622 - val_rmse: 0.5120 - learning_rate: 5.0000e-04\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "LSTM 1 output (FLOW) -> RMSE: 0.541, MAE: 0.328, R2: 0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal-flow\n",
    "#split data\n",
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "X_train = df_train[flow_features_same].values\n",
    "y_train = df_train['FLOW_future_sum'].values\n",
    "X_test = df_test[flow_features_same].values\n",
    "y_test = df_test['FLOW_future_sum'].values\n",
    "\n",
    "#create sequences\n",
    "X_train_seq, y_train_seq = create_sequences_sum(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_sum(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "#scale data\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "#for saving\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_flow_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "#create model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#train model with 20% validation\n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "#predict (directly 1 output)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "rmse = mean_squared_error(y_test_scaled, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "07e154bd-b73e-458d-9e09-649b13c6b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - loss: 0.4508 - rmse: 0.6714 - val_loss: 0.3082 - val_rmse: 0.5552 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - loss: 0.4152 - rmse: 0.6443 - val_loss: 0.3066 - val_rmse: 0.5537 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - loss: 0.4037 - rmse: 0.6354 - val_loss: 0.3015 - val_rmse: 0.5491 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - loss: 0.3975 - rmse: 0.6304 - val_loss: 0.3394 - val_rmse: 0.5826 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - loss: 0.3908 - rmse: 0.6251 - val_loss: 0.2969 - val_rmse: 0.5448 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - loss: 0.3842 - rmse: 0.6199 - val_loss: 0.3126 - val_rmse: 0.5591 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - loss: 0.3800 - rmse: 0.6165 - val_loss: 0.3060 - val_rmse: 0.5532 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - loss: 0.3804 - rmse: 0.6168 - val_loss: 0.3325 - val_rmse: 0.5766 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - loss: 0.3702 - rmse: 0.6084 - val_loss: 0.3354 - val_rmse: 0.5791 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - loss: 0.3692 - rmse: 0.6077 - val_loss: 0.3156 - val_rmse: 0.5618 - learning_rate: 5.0000e-04\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "LSTM 1 output (SPEED) -> RMSE: 1.003, MAE: 0.530, R2: 0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the same portal-speed\n",
    "\n",
    "#split data\n",
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "X_train = df_train[speed_features_same_nl].values\n",
    "y_train = df_train['SPEED_future_mean'].values\n",
    "X_test = df_test[speed_features_same_nl].values\n",
    "y_test = df_test['SPEED_future_mean'].values\n",
    "\n",
    "#create sequences\n",
    "X_train_seq, y_train_seq = create_sequences_mean(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_mean(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "#scale data\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "\n",
    "#for saving\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_speed_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "#create model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#fit training data wit h20% validation\n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "\n",
    "#predict (directly 1 output)\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_true = y_scaler.inverse_transform(y_test_scaled)\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c7aeb5b2-c985-47cb-9599-d777b013feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1518 - rmse: 0.3896 - val_loss: 0.2617 - val_rmse: 0.5116 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1194 - rmse: 0.3455 - val_loss: 0.2489 - val_rmse: 0.4989 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1129 - rmse: 0.3361 - val_loss: 0.2693 - val_rmse: 0.5190 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1097 - rmse: 0.3313 - val_loss: 0.2553 - val_rmse: 0.5053 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1082 - rmse: 0.3290 - val_loss: 0.2957 - val_rmse: 0.5438 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1018 - rmse: 0.3191 - val_loss: 0.2295 - val_rmse: 0.4790 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0995 - rmse: 0.3154 - val_loss: 0.2269 - val_rmse: 0.4764 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0985 - rmse: 0.3139 - val_loss: 0.2345 - val_rmse: 0.4843 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0968 - rmse: 0.3112 - val_loss: 0.2328 - val_rmse: 0.4825 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0946 - rmse: 0.3076 - val_loss: 0.2372 - val_rmse: 0.4871 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0913 - rmse: 0.3021 - val_loss: 0.2305 - val_rmse: 0.4801 - learning_rate: 2.5000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0898 - rmse: 0.2997 - val_loss: 0.2327 - val_rmse: 0.4824 - learning_rate: 2.5000e-04\n",
      "\u001b[1m1880/1880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
      "LSTM 1 output (FLOW) -> RMSE: 0.436, MAE: 0.278, R2: 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal-flow\n",
    "\n",
    "#split data\n",
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "X_train = df_train[flow_features_neighbour_nl].values\n",
    "y_train = df_train['FLOW_future_sum'].values\n",
    "X_test = df_test[flow_features_neighbour_nl].values\n",
    "y_test = df_test['FLOW_future_sum'].values\n",
    "\n",
    "#create sequence\n",
    "X_train_seq, y_train_seq = create_sequences_sum(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_sum(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "#scale data\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "#for saving\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_flow_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "#create model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#train model \n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "#predict model (directly one output)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "rmse = mean_squared_error(y_test_scaled, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "2fa1ae4d-83ff-4e3f-bbf6-cb66a1088180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - loss: 0.4918 - rmse: 0.7013 - val_loss: 0.3625 - val_rmse: 0.6020 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - loss: 0.4606 - rmse: 0.6787 - val_loss: 0.3754 - val_rmse: 0.6127 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - loss: 0.4534 - rmse: 0.6733 - val_loss: 0.3723 - val_rmse: 0.6102 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.4425 - rmse: 0.6652 - val_loss: 0.4009 - val_rmse: 0.6332 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.4383 - rmse: 0.6620 - val_loss: 0.3892 - val_rmse: 0.6239 - learning_rate: 5.0000e-04\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "LSTM 1 output (SPEED) -> RMSE: 1.085, MAE: 0.576, R2: 0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#prediction from sensors in the neighbour portal-speed\n",
    "#split data\n",
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "X_train = df_train[speed_features_neighbour_nl].values\n",
    "y_train = df_train['SPEED_future_mean'].values\n",
    "X_test = df_test[speed_features_neighbour_nl].values\n",
    "y_test = df_test['SPEED_future_mean'].values\n",
    "\n",
    "#create sequence\n",
    "X_train_seq, y_train_seq = create_sequences_mean(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_mean(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "#scale data\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "#for saving\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_speed_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "#create model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "#compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#train model\n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "#predict (directly 1 output)\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "y_true = y_scaler.inverse_transform(y_test_scaled)\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fb46b-7dc9-45ce-8699-2911188db650",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e918b-573e-4266-a1c6-78271bed477a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
