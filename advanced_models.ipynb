{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7768fd51-9f7b-4fd1-89f7-ce9bb3043009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75c90a7d-5da1-483e-bae3-efadce722ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from scikeras) (3.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from scikeras) (1.4.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from keras>=3.2.0->scikeras) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.5.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from keras>=3.2.0->scikeras) (25.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\johanna\\anaconda3\\envs\\ai_project\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "41a6217c-7087-4837-8f49-17e63cf13968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras.layers import  Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aabf74bb-a1c9-4222-a454-9b31c8d8a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lagged_all = pd.read_parquet(\"data/processed/df_lagged_30_all.parquet\")\n",
    "df_lagged_all = pd.read_parquet(\"data/processed/df_lagged_all.parquet\")\n",
    "df_lagged_all_peak = pd.read_parquet(\"data/processed/df_lagged_all_peak.parquet\")\n",
    "\n",
    "df_2_full = pd.read_parquet(\"data/processed/df_2_full_v2.parquet\")\n",
    "\n",
    "df_all=pd.read_parquet(\"data/processed/df_all.parquet\")\n",
    "df_all_peak= df_all.set_index(\"Datetime\").between_time(\"07:15\", \"08:30\").reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac797839-78ec-4f39-b417-f351d8b13d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sensor = 1076\n",
    "same_portal=\"55620\"\n",
    "neighbour_portal = \"56160\"\n",
    "\n",
    "same_portal_sensors = df_2_full[df_2_full['PORTAL_clean'] == same_portal]['DP_ID'].unique()\n",
    "same_sensors = [s for s in same_portal_sensors if s != target_sensor]\n",
    "\n",
    "\n",
    "neighbour_sensors = df_2_full[df_2_full['PORTAL_clean'] == neighbour_portal]['DP_ID'].unique()\n",
    "all_sensors=df_2_full['DP_ID'].unique()\n",
    "except_target_sensors = [s for s in all_sensors if s != target_sensor]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f5972f6-5842-446d-8b73-a14928be0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlags=15\n",
    "#nlags=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3c27edb9-8c27-4658-8c63-b99c6a27ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "flow_features_same = [\n",
    "    f'SENSOR_{sensor}_FLOW_lag_{i+1}'\n",
    "    for sensor in same_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "flow_features_neighbour = [\n",
    "    f'SENSOR_{sensor}_FLOW_lag_{i+1}'\n",
    "    for sensor in neighbour_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "speed_features_same = [\n",
    "    f'SENSOR_{sensor}_SPEED_lag_{i+1}'\n",
    "    for sensor in same_sensors\n",
    "    for i in range(nlags)\n",
    "]\n",
    "speed_features_neighbour = [\n",
    "    f'SENSOR_{sensor}_SPEED_lag_{i+1}'\n",
    "    for sensor in neighbour_sensors\n",
    "    for i in range(nlags)\n",
    "]        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2466b25-b0cf-45cb-b70b-70174bae1b91",
   "metadata": {},
   "source": [
    "xgb-boost : hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "af1686c7-bfb7-4658-a21f-a180081a716a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>SENSOR_539_FLOW_lag_1</th>\n",
       "      <th>SENSOR_539_FLOW_lag_2</th>\n",
       "      <th>SENSOR_539_FLOW_lag_3</th>\n",
       "      <th>SENSOR_539_FLOW_lag_4</th>\n",
       "      <th>SENSOR_539_FLOW_lag_5</th>\n",
       "      <th>SENSOR_539_FLOW_lag_6</th>\n",
       "      <th>SENSOR_539_FLOW_lag_7</th>\n",
       "      <th>SENSOR_539_FLOW_lag_8</th>\n",
       "      <th>SENSOR_539_FLOW_lag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>SENSOR_1254_SPEED_lag_10</th>\n",
       "      <th>SENSOR_1254_SPEED_lag_11</th>\n",
       "      <th>SENSOR_1254_SPEED_lag_12</th>\n",
       "      <th>SENSOR_1254_SPEED_lag_13</th>\n",
       "      <th>SENSOR_1254_SPEED_lag_14</th>\n",
       "      <th>SENSOR_1254_SPEED_lag_15</th>\n",
       "      <th>FLOW_filled</th>\n",
       "      <th>SPEED_MS_AVG_filled</th>\n",
       "      <th>FLOW_future_sum</th>\n",
       "      <th>SPEED_future_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01 07:30:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>23.17</td>\n",
       "      <td>23.56</td>\n",
       "      <td>24.36</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.95</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01 07:31:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.27</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>23.17</td>\n",
       "      <td>23.56</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.36</td>\n",
       "      <td>311.0</td>\n",
       "      <td>18.148667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01 07:32:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.91</td>\n",
       "      <td>22.27</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>23.17</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.53</td>\n",
       "      <td>309.0</td>\n",
       "      <td>18.065333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01 07:33:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.80</td>\n",
       "      <td>23.91</td>\n",
       "      <td>22.27</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>22.30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.97</td>\n",
       "      <td>310.0</td>\n",
       "      <td>17.988667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01 07:34:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.79</td>\n",
       "      <td>22.80</td>\n",
       "      <td>23.91</td>\n",
       "      <td>22.27</td>\n",
       "      <td>22.30</td>\n",
       "      <td>22.35</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>307.0</td>\n",
       "      <td>17.882000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime  SENSOR_539_FLOW_lag_1  SENSOR_539_FLOW_lag_2  \\\n",
       "0 2021-06-01 07:30:00                   17.0                   11.0   \n",
       "1 2021-06-01 07:31:00                   12.0                   17.0   \n",
       "2 2021-06-01 07:32:00                   17.0                   12.0   \n",
       "3 2021-06-01 07:33:00                   12.0                   17.0   \n",
       "4 2021-06-01 07:34:00                   15.0                   12.0   \n",
       "\n",
       "   SENSOR_539_FLOW_lag_3  SENSOR_539_FLOW_lag_4  SENSOR_539_FLOW_lag_5  \\\n",
       "0                   18.0                   13.0                   20.0   \n",
       "1                   11.0                   18.0                   13.0   \n",
       "2                   17.0                   11.0                   18.0   \n",
       "3                   12.0                   17.0                   11.0   \n",
       "4                   17.0                   12.0                   17.0   \n",
       "\n",
       "   SENSOR_539_FLOW_lag_6  SENSOR_539_FLOW_lag_7  SENSOR_539_FLOW_lag_8  \\\n",
       "0                   13.0                   18.0                   10.0   \n",
       "1                   20.0                   13.0                   18.0   \n",
       "2                   13.0                   20.0                   13.0   \n",
       "3                   18.0                   13.0                   20.0   \n",
       "4                   11.0                   18.0                   13.0   \n",
       "\n",
       "   SENSOR_539_FLOW_lag_9  ...  SENSOR_1254_SPEED_lag_10  \\\n",
       "0                   17.0  ...                     22.30   \n",
       "1                   10.0  ...                     22.27   \n",
       "2                   18.0  ...                     23.91   \n",
       "3                   13.0  ...                     22.80   \n",
       "4                   20.0  ...                     22.79   \n",
       "\n",
       "   SENSOR_1254_SPEED_lag_11  SENSOR_1254_SPEED_lag_12  \\\n",
       "0                     22.35                     22.30   \n",
       "1                     22.30                     22.35   \n",
       "2                     22.27                     22.30   \n",
       "3                     23.91                     22.27   \n",
       "4                     22.80                     23.91   \n",
       "\n",
       "   SENSOR_1254_SPEED_lag_13  SENSOR_1254_SPEED_lag_14  \\\n",
       "0                     23.17                     23.56   \n",
       "1                     22.30                     23.17   \n",
       "2                     22.35                     22.30   \n",
       "3                     22.30                     22.35   \n",
       "4                     22.27                     22.30   \n",
       "\n",
       "   SENSOR_1254_SPEED_lag_15  FLOW_filled  SPEED_MS_AVG_filled  \\\n",
       "0                     24.36         16.0                18.95   \n",
       "1                     23.56         20.0                18.36   \n",
       "2                     23.17         19.0                18.53   \n",
       "3                     22.30         19.0                19.97   \n",
       "4                     22.35         17.0                19.69   \n",
       "\n",
       "   FLOW_future_sum  SPEED_future_mean  \n",
       "0            304.0          18.292000  \n",
       "1            311.0          18.148667  \n",
       "2            309.0          18.065333  \n",
       "3            310.0          17.988667  \n",
       "4            307.0          17.882000  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged_all_peak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a65de289-ff0f-4bbc-bca0-7a623f17634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train, df_test = train_test_split(df_lagged_all_peak, test_size=0.2, random_state=42)\n",
    "df_train, df_test = train_test_split(df_lagged_all, test_size=0.2, random_state=42)\n",
    "\n",
    "#split_time = df_2_full['Datetime'].quantile(0.8)\n",
    "#print(split_time)\n",
    "\n",
    "#df_train = df_lagged_all[df_lagged_all['Datetime'] <= split_time]\n",
    "#df_test = df_lagged_all[df_lagged_all['Datetime'] > split_time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f1cf3a3b-e25d-425b-bd55-9a52baf9e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.001,0.005,0.01, 0.05],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b359e1cf-6971-4402-8351-98cabfaa939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Beste Parameter (FLOW): {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (FLOW) -> RMSE: 24.194, MAE: 18.232, R²: 0.834\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter (FLOW): {'subsample': 0.6, 'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.564, MAE: 0.329, R²: 0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "random_search_flow = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # Anzahl zufälliger Kombinationen\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "random_search_flow.fit(df_train[flow_features_same], df_train[\"FLOW_future_sum\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_flow.best_params_)\n",
    "model_flow = random_search_flow.best_estimator_\n",
    "model_flow.save_model(\"model/xgb_flow_same.json\")\n",
    "\n",
    "y_pred = model_flow.predict(df_test[flow_features_same])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "random_search_speed = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # Anzahl zufälliger Kombinationen\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "\n",
    "random_search_speed.fit(df_train[speed_features_same], df_train[\"SPEED_future_mean\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_speed.best_params_)\n",
    "model_speed = random_search_speed.best_estimator_\n",
    "\n",
    "y_pred = model_speed.predict(df_test[speed_features_same])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8c16d6f1-4dd1-4fac-a0d5-19846c3a7caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Beste Parameter (FLOW): {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (FLOW) -> RMSE: 20.202, MAE: 15.353, R²: 0.884\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter (FLOW): {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 0.6}\n",
      "XGBoost Regression (SPEED) -> RMSE: 0.632, MAE: 0.332, R²: 0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#neighbour portal\n",
    "\n",
    "random_search_flow = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # Anzahl zufälliger Kombinationen\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "random_search_flow.fit(df_train[flow_features_neighbour], df_train[\"FLOW_future_sum\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_flow.best_params_)\n",
    "model_flow = random_search_flow.best_estimator_\n",
    "y_pred = model_flow.predict(df_test[flow_features_neighbour])\n",
    "y_test = df_test['FLOW_future_sum']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "random_search_speed = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # Anzahl zufälliger Kombinationen\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "\n",
    "random_search_speed.fit(df_train[speed_features_neighbour], df_train[\"SPEED_future_mean\"])\n",
    "print(\"Beste Parameter (FLOW):\", random_search_speed.best_params_)\n",
    "model_speed = random_search_speed.best_estimator_\n",
    "\n",
    "y_pred = model_speed.predict(df_test[speed_features_neighbour])\n",
    "y_test = df_test['SPEED_future_mean']\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Regression (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f597a15-b86d-4f1f-9416-95e166f15ad4",
   "metadata": {},
   "source": [
    "Feedforward Neural Network (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "14177efa-8919-49c5-9c1c-5b69343236dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fast forward NN (FLOW) -> RMSE: 25.268, MAE: 19.388, R²: 0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Fast forward NN (SPEED) -> RMSE: 0.642, MAE: 0.355, R²: 0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[flow_features_same])\n",
    "X_test_scaled  = scaler.transform(df_test[flow_features_same])\n",
    "\n",
    "\n",
    "model_flow= Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Eingabeschicht\n",
    "    Dense(32, activation='relu'),                                           # Versteckte Schicht\n",
    "    Dense(16, activation='relu'),                                           # Weitere versteckte Schicht\n",
    "    Dense(1)                                                                 # Ausgangsschicht für Regression\n",
    "])\n",
    "\n",
    "model_flow.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history_flow = model_flow.fit(\n",
    "    X_train_scaled, df_train[\"FLOW_future_sum\"],\n",
    "    validation_split=0.2,  # 20% der Trainingsdaten für Validierung\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model_flow.predict(X_test_scaled)\n",
    "y_test=df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[speed_features_same])\n",
    "X_test_scaled  = scaler.transform(df_test[speed_features_same])\n",
    "\n",
    "model_speed = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Eingabeschicht\n",
    "    Dense(32, activation='relu'),                                           # Versteckte Schicht\n",
    "    Dense(16, activation='relu'),                                           # Weitere versteckte Schicht\n",
    "    Dense(1)                                                                 # Ausgangsschicht für Regression\n",
    "])\n",
    "\n",
    "model_speed.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history_speed = model_speed.fit(\n",
    "    X_train_scaled, df_train[\"SPEED_future_mean\"],\n",
    "    validation_split=0.2,  # 20% der Trainingsdaten für Validierung\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(X_test_scaled)\n",
    "y_test=df_test[\"SPEED_future_mean\"]\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ca849db4-1240-4f02-947c-5ea3869862ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fast forward NN (FLOW) -> RMSE: 22.509, MAE: 17.109, R²: 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fast forward NN (SPEED) -> RMSE: 0.695, MAE: 0.375, R²: 0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[flow_features_neighbour])\n",
    "X_test_scaled  = scaler.transform(df_test[flow_features_neighbour])\n",
    "\n",
    "\n",
    "model_flow= Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Eingabeschicht\n",
    "    Dense(32, activation='relu'),                                           # Versteckte Schicht\n",
    "    Dense(16, activation='relu'),                                           # Weitere versteckte Schicht\n",
    "    Dense(1)                                                                 # Ausgangsschicht für Regression\n",
    "])\n",
    "\n",
    "model_flow.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history_flow = model_flow.fit(\n",
    "    X_train_scaled, df_train[\"FLOW_future_sum\"],\n",
    "    validation_split=0.2,  # 20% der Trainingsdaten für Validierung\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model_flow.predict(X_test_scaled)\n",
    "y_test=df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[speed_features_neighbour])\n",
    "X_test_scaled  = scaler.transform(df_test[speed_features_neighbour])\n",
    "\n",
    "model_speed = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Eingabeschicht\n",
    "    Dense(32, activation='relu'),                                           # Versteckte Schicht\n",
    "    Dense(16, activation='relu'),                                           # Weitere versteckte Schicht\n",
    "    Dense(1)                                                                 # Ausgangsschicht für Regression\n",
    "])\n",
    "\n",
    "model_speed.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "history_speed = model_speed.fit(\n",
    "    X_train_scaled, df_train[\"SPEED_future_mean\"],\n",
    "    validation_split=0.2,  # 20% der Trainingsdaten für Validierung\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "y_pred = model_speed.predict(X_test_scaled)\n",
    "y_test=df_test[\"SPEED_future_mean\"]\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Fast forward NN (SPEED) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "52b97f1d-c885-4d1d-93bd-f1c9dfe2e7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/scaler_flow_same.pkl']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_flow_same = StandardScaler()\n",
    "X_train_scaled = scaler_flow_same.fit_transform(df_train[flow_features_same])\n",
    "X_test_scaled  = scaler_flow_same.transform(df_test[flow_features_same])\n",
    "joblib.dump(scaler_flow_same, \"model/scaler_flow_same.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d48647a9-4747-4637-a548-8335a8094185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\308595228.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse   val_rmse\n",
      "0              16             2          0.00   29.371403  29.733335\n",
      "1              16             2          0.05   37.075043  33.153324\n",
      "2              16             2          0.10   42.041279  33.635246\n",
      "3              16             3          0.00   27.912714  28.976200\n",
      "4              16             3          0.05   39.897415  33.503639\n",
      "5              16             3          0.10   43.846443  34.295017\n",
      "6              16             4          0.00   28.486589  29.510708\n",
      "7              16             4          0.05   36.866894  31.401754\n",
      "8              16             4          0.10   40.082947  31.197016\n",
      "9              32             2          0.00   28.014595  29.070684\n",
      "10             32             2          0.05   32.399998  30.271238\n",
      "11             32             2          0.10   34.075420  30.764746\n",
      "12             32             3          0.00   27.727701  29.272102\n",
      "13             32             3          0.05   32.647373  30.021769\n",
      "14             32             3          0.10   35.011250  31.629435\n",
      "15             32             4          0.00   28.093256  29.142313\n",
      "16             32             4          0.05   31.315088  29.387403\n",
      "17             32             4          0.10   35.715744  31.192465\n",
      "18             64             2          0.00   27.472795  29.341480\n",
      "19             64             2          0.05   32.532330  30.811172\n",
      "20             64             2          0.10   33.490093  30.293657\n",
      "21             64             3          0.00   28.851919  29.869560\n",
      "22             64             3          0.05   30.222097  29.404978\n",
      "23             64             3          0.10   31.837008  29.717525\n",
      "24             64             4          0.00   27.025183  28.974485\n",
      "25             64             4          0.05   30.128540  29.311167\n",
      "26             64             4          0.10   32.301857  29.614431\n",
      "27            128             2          0.00   27.893883  29.641785\n",
      "28            128             2          0.05   30.282890  29.778042\n",
      "29            128             2          0.10   31.468235  30.192453\n",
      "30            128             3          0.00   27.376104  29.253227\n",
      "31            128             3          0.05   28.109545  28.893290\n",
      "32            128             3          0.10   28.693462  29.138802\n",
      "33            128             4          0.00   28.150019  29.234877\n",
      "34            128             4          0.05   29.346590  29.468685\n",
      "35            128             4          0.10   30.588945  29.653276\n",
      "Epoch 1/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 891us/step - loss: 1731.5171 - rmse: 41.6115 - val_loss: 1050.1238 - val_rmse: 32.4056 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - loss: 1095.2737 - rmse: 33.0949 - val_loss: 1041.9083 - val_rmse: 32.2786 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - loss: 1052.7274 - rmse: 32.4458 - val_loss: 964.5223 - val_rmse: 31.0568 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - loss: 1027.7020 - rmse: 32.0578 - val_loss: 976.1412 - val_rmse: 31.2433 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 994.6746 - rmse: 31.5385 - val_loss: 1033.4736 - val_rmse: 32.1477 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - loss: 981.7228 - rmse: 31.3325 - val_loss: 985.1785 - val_rmse: 31.3876 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 914.6654 - rmse: 30.2434 - val_loss: 898.3356 - val_rmse: 29.9722 - learning_rate: 0.0050\n",
      "Epoch 8/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 913.1998 - rmse: 30.2192 - val_loss: 908.3728 - val_rmse: 30.1392 - learning_rate: 0.0050\n",
      "Epoch 9/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - loss: 905.7272 - rmse: 30.0953 - val_loss: 921.6393 - val_rmse: 30.3585 - learning_rate: 0.0050\n",
      "Epoch 10/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - loss: 898.9813 - rmse: 29.9830 - val_loss: 892.2537 - val_rmse: 29.8706 - learning_rate: 0.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - loss: 899.8989 - rmse: 29.9983 - val_loss: 1066.1420 - val_rmse: 32.6518 - learning_rate: 0.0050\n",
      "Epoch 12/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 887.7765 - rmse: 29.7956 - val_loss: 887.4865 - val_rmse: 29.7907 - learning_rate: 0.0050\n",
      "Epoch 13/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 885.9044 - rmse: 29.7641 - val_loss: 896.2809 - val_rmse: 29.9380 - learning_rate: 0.0050\n",
      "Epoch 14/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 870.7873 - rmse: 29.5091 - val_loss: 896.1351 - val_rmse: 29.9355 - learning_rate: 0.0050\n",
      "Epoch 15/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - loss: 866.4787 - rmse: 29.4360 - val_loss: 885.2903 - val_rmse: 29.7538 - learning_rate: 0.0050\n",
      "Epoch 16/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 847.0215 - rmse: 29.1036 - val_loss: 859.8157 - val_rmse: 29.3226 - learning_rate: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - loss: 828.8560 - rmse: 28.7899 - val_loss: 861.1297 - val_rmse: 29.3450 - learning_rate: 0.0050\n",
      "Epoch 18/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 817.4312 - rmse: 28.5908 - val_loss: 861.0536 - val_rmse: 29.3437 - learning_rate: 0.0050\n",
      "Epoch 19/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 811.1301 - rmse: 28.4803 - val_loss: 910.0776 - val_rmse: 30.1675 - learning_rate: 0.0050\n",
      "Epoch 20/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - loss: 776.3370 - rmse: 27.8628 - val_loss: 855.3643 - val_rmse: 29.2466 - learning_rate: 0.0025\n",
      "Epoch 21/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 767.4539 - rmse: 27.7030 - val_loss: 882.0974 - val_rmse: 29.7001 - learning_rate: 0.0025\n",
      "Epoch 22/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 762.5419 - rmse: 27.6142 - val_loss: 866.0720 - val_rmse: 29.4291 - learning_rate: 0.0025\n",
      "Epoch 23/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 759.6696 - rmse: 27.5621 - val_loss: 854.6257 - val_rmse: 29.2340 - learning_rate: 0.0025\n",
      "Epoch 24/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 753.4178 - rmse: 27.4485 - val_loss: 866.6935 - val_rmse: 29.4397 - learning_rate: 0.0025\n",
      "Epoch 25/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - loss: 753.2640 - rmse: 27.4457 - val_loss: 858.0863 - val_rmse: 29.2931 - learning_rate: 0.0025\n",
      "Epoch 26/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - loss: 745.8684 - rmse: 27.3106 - val_loss: 891.2662 - val_rmse: 29.8541 - learning_rate: 0.0025\n",
      "Epoch 27/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 724.6740 - rmse: 26.9198 - val_loss: 866.9536 - val_rmse: 29.4441 - learning_rate: 0.0012\n",
      "Epoch 28/100\n",
      "\u001b[1m1460/1460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 720.0946 - rmse: 26.8346 - val_loss: 870.4365 - val_rmse: 29.5032 - learning_rate: 0.0012\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step\n",
      "Best FLOW NN -> RMSE: 28.720, MAE: 20.481, R²: 0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#same portal-flow\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[flow_features_same])\n",
    "X_test_scaled  = scaler.transform(df_test[flow_features_same])\n",
    "y_train = df_train[\"FLOW_future_sum\"]\n",
    "y_test = df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "\n",
    "for neurons in number_neurons:\n",
    "    for num_layer in number_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = Sequential()\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "    \n",
    "            hist = model.fit(\n",
    "                X_train_scaled, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            # Ergebnisse speichern\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            it_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "# Übersicht\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_flow_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "# Training\n",
    "best_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Testbewertung\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best FLOW NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "504234d9-a1e8-4950-8621-32e21fe32cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/scaler_speed_same.pkl']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_speed_same = StandardScaler()\n",
    "X_train_scaled = scaler_speed_same.fit_transform(df_train[speed_features_same])\n",
    "X_test_scaled  = scaler_speed_same.transform(df_test[speed_features_same])\n",
    "joblib.dump(scaler_speed_same, \"model/scaler_speed_same.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26e8c8c5-50a9-425d-8f1f-b9b940d4e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\867997906.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse  val_rmse\n",
      "0              16             2          0.00    0.805148  0.790606\n",
      "1              16             2          0.05    0.973746  0.811842\n",
      "2              16             2          0.10    0.822249  0.793180\n",
      "3              16             3          0.00    0.733872  0.737610\n",
      "4              16             3          0.05    0.812134  0.754808\n",
      "5              16             3          0.10    0.878491  0.784833\n",
      "6              16             4          0.00    0.777013  0.766441\n",
      "7              16             4          0.05    0.817865  0.782449\n",
      "8              16             4          0.10    0.857271  0.780539\n",
      "9              32             2          0.00    0.718395  0.731156\n",
      "10             32             2          0.05    0.779175  0.755556\n",
      "11             32             2          0.10    0.830919  0.771503\n",
      "12             32             3          0.00    0.753205  0.745721\n",
      "13             32             3          0.05    0.945618  0.791097\n",
      "14             32             3          0.10    0.839426  0.774840\n",
      "15             32             4          0.00    0.817331  0.776057\n",
      "16             32             4          0.05    0.826668  0.770087\n",
      "17             32             4          0.10    0.865351  0.774622\n",
      "18             64             2          0.00    0.726241  0.732919\n",
      "19             64             2          0.05    0.775880  0.740514\n",
      "20             64             2          0.10    0.784956  0.756553\n",
      "21             64             3          0.00    0.869865  0.817201\n",
      "22             64             3          0.05    0.809672  0.757874\n",
      "23             64             3          0.10    0.927092  0.805171\n",
      "24             64             4          0.00    0.888662  0.800578\n",
      "25             64             4          0.05    0.826923  0.755538\n",
      "26             64             4          0.10    1.077974  0.812046\n",
      "27            128             2          0.00    0.775472  0.756554\n",
      "28            128             2          0.05    0.764023  0.731291\n",
      "29            128             2          0.10    0.917648  0.782089\n",
      "30            128             3          0.00    0.744699  0.737121\n",
      "31            128             3          0.05    0.859786  0.754419\n",
      "32            128             3          0.10    0.862830  0.780701\n",
      "33            128             4          0.00    0.793643  0.794060\n",
      "34            128             4          0.05    1.077041  0.858270\n",
      "35            128             4          0.10    0.951876  0.796824\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step\n",
      "Best SPEED NN -> RMSE: 0.805, MAE: 0.419, R²: 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#same portal-speed\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[speed_features_same])\n",
    "X_test_scaled  = scaler.transform(df_test[speed_features_same])\n",
    "y_train = df_train[\"SPEED_future_mean\"]\n",
    "y_test = df_test[\"SPEED_future_mean\"]\n",
    "\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "\n",
    "for neurons in number_neurons:\n",
    "    for num_layer in number_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = Sequential()\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "    \n",
    "            # Optional: speichern der besten Gewichte\n",
    "            #checkpoint = ModelCheckpoint(\"model/NN_model_speed_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "    \n",
    "            hist = model.fit(\n",
    "                X_train_scaled, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            # Ergebnisse speichern\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            it_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "# Übersicht\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_speed_same_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "# Training\n",
    "best_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Testbewertung\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best SPEED NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22653b62-c1f5-490b-9496-87c46238288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\2257366272.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse   val_rmse\n",
      "0              16             2          0.00   24.768108  25.254890\n",
      "1              16             2          0.05   29.870770  26.075983\n",
      "2              16             2          0.10   33.876259  25.873125\n",
      "3              16             3          0.00   23.947803  24.581074\n",
      "4              16             3          0.05   32.065853  28.567739\n",
      "5              16             3          0.10   34.205040  26.713118\n",
      "6              16             4          0.00   24.628374  25.154072\n",
      "7              16             4          0.05   31.729382  27.132214\n",
      "8              16             4          0.10   33.573238  27.741846\n",
      "9              32             2          0.00   23.871603  24.740385\n",
      "10             32             2          0.05   28.478031  25.412991\n",
      "11             32             2          0.10   29.893749  25.724424\n",
      "12             32             3          0.00   23.454884  24.592428\n",
      "13             32             3          0.05   27.005396  24.729988\n",
      "14             32             3          0.10   28.438347  24.731655\n",
      "15             32             4          0.00   24.006987  24.754995\n",
      "16             32             4          0.05   29.598333  25.834652\n",
      "17             32             4          0.10   31.037954  25.666662\n",
      "18             64             2          0.00   23.552530  24.551559\n",
      "19             64             2          0.05   27.162569  25.262213\n",
      "20             64             2          0.10   30.057209  26.172491\n",
      "21             64             3          0.00   23.170532  24.796612\n",
      "22             64             3          0.05   25.607405  24.497496\n",
      "23             64             3          0.10   26.509783  24.817190\n",
      "24             64             4          0.00   23.471045  24.647360\n",
      "25             64             4          0.05   26.190321  24.921551\n",
      "26             64             4          0.10   30.408360  27.010319\n",
      "27            128             2          0.00   23.614721  24.654772\n",
      "28            128             2          0.05   25.052713  24.795582\n",
      "29            128             2          0.10   27.073999  25.192635\n",
      "30            128             3          0.00   23.714266  25.001190\n",
      "31            128             3          0.05   24.348314  24.660208\n",
      "32            128             3          0.10   24.832069  24.943247\n",
      "33            128             4          0.00   23.297321  24.700212\n",
      "34            128             4          0.05   26.094875  25.349012\n",
      "35            128             4          0.10   30.004120  26.820402\n",
      "64 3 0\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step\n",
      "Best FLOW NN -> RMSE: 24.511, MAE: 17.286, R²: 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#neighbour portal-flow\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[flow_features_neighbour])\n",
    "X_test_scaled  = scaler.transform(df_test[flow_features_neighbour])\n",
    "y_train = df_train[\"FLOW_future_sum\"]\n",
    "y_test = df_test[\"FLOW_future_sum\"]\n",
    "\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "\n",
    "for neurons in number_neurons:\n",
    "    for num_layer in number_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = Sequential()\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "    \n",
    "            # Optional: speichern der besten Gewichte\n",
    "            #checkpoint = ModelCheckpoint(\"model/NN_model_flow_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "    \n",
    "            hist = model.fit(\n",
    "                X_train_scaled, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            # Ergebnisse speichern\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            it_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "# Übersicht\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "print(best_neurons, best_layers, best_dropout)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_flow_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "# Training\n",
    "best_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Testbewertung\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best FLOW NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a4e83b5-2ba0-47f7-b459-24e59f4989bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\AppData\\Local\\Temp\\ipykernel_10492\\326426236.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2 0.0 done\n",
      "16 2 0.05 done\n",
      "16 2 0.1 done\n",
      "16 3 0.0 done\n",
      "16 3 0.05 done\n",
      "16 3 0.1 done\n",
      "16 4 0.0 done\n",
      "16 4 0.05 done\n",
      "16 4 0.1 done\n",
      "32 2 0.0 done\n",
      "32 2 0.05 done\n",
      "32 2 0.1 done\n",
      "32 3 0.0 done\n",
      "32 3 0.05 done\n",
      "32 3 0.1 done\n",
      "32 4 0.0 done\n",
      "32 4 0.05 done\n",
      "32 4 0.1 done\n",
      "64 2 0.0 done\n",
      "64 2 0.05 done\n",
      "64 2 0.1 done\n",
      "64 3 0.0 done\n",
      "64 3 0.05 done\n",
      "64 3 0.1 done\n",
      "64 4 0.0 done\n",
      "64 4 0.05 done\n",
      "64 4 0.1 done\n",
      "128 2 0.0 done\n",
      "128 2 0.05 done\n",
      "128 2 0.1 done\n",
      "128 3 0.0 done\n",
      "128 3 0.05 done\n",
      "128 3 0.1 done\n",
      "128 4 0.0 done\n",
      "128 4 0.05 done\n",
      "128 4 0.1 done\n",
      "   number_neurons number_layers  dropout_rate  train_rmse  val_rmse\n",
      "0              16             2          0.00    0.917047  0.926511\n",
      "1              16             2          0.05    0.908428  0.900218\n",
      "2              16             2          0.10    0.936143  0.904106\n",
      "3              16             3          0.00    0.855502  0.891089\n",
      "4              16             3          0.05    0.913606  0.893798\n",
      "5              16             3          0.10    0.961896  0.917284\n",
      "6              16             4          0.00    0.858055  0.892206\n",
      "7              16             4          0.05    0.901608  0.892986\n",
      "8              16             4          0.10    0.953182  0.898682\n",
      "9              32             2          0.00    0.870039  0.893049\n",
      "10             32             2          0.05    1.013831  0.976710\n",
      "11             32             2          0.10    0.983026  0.973556\n",
      "12             32             3          0.00    0.881280  0.899969\n",
      "13             32             3          0.05    1.059069  0.964000\n",
      "14             32             3          0.10    0.890266  0.887247\n",
      "15             32             4          0.00    0.911515  0.947719\n",
      "16             32             4          0.05    1.002717  0.949513\n",
      "17             32             4          0.10    0.917669  0.901365\n",
      "18             64             2          0.00    0.865058  0.900217\n",
      "19             64             2          0.05    0.901713  0.884898\n",
      "20             64             2          0.10    0.873667  0.883873\n",
      "21             64             3          0.00    1.011136  0.965759\n",
      "22             64             3          0.05    0.973729  0.924550\n",
      "23             64             3          0.10    0.887519  0.887344\n",
      "24             64             4          0.00    0.955478  0.946387\n",
      "25             64             4          0.05    1.154971  1.002804\n",
      "26             64             4          0.10    0.923697  0.901611\n",
      "27            128             2          0.00    0.899512  0.908445\n",
      "28            128             2          0.05    1.017718  0.968171\n",
      "29            128             2          0.10    0.866816  0.877788\n",
      "30            128             3          0.00    1.006634  1.008220\n",
      "31            128             3          0.05    1.068124  1.003751\n",
      "32            128             3          0.10    0.906062  0.895106\n",
      "33            128             4          0.00    1.034620  0.973314\n",
      "34            128             4          0.05    1.148691  0.969545\n",
      "35            128             4          0.10    1.308806  1.123274\n",
      "128 2 0\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step\n",
      "Best SPEED NN -> RMSE: 0.934, MAE: 0.437, R²: 0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#neighbour portal-speed\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[speed_features_neighbour])\n",
    "X_test_scaled  = scaler.transform(df_test[speed_features_neighbour])\n",
    "y_train = df_train[\"SPEED_future_mean\"]\n",
    "y_test = df_test[\"SPEED_future_mean\"]\n",
    "\n",
    "number_neurons = [16, 32, 64, 128]\n",
    "number_layers = [2, 3,4]\n",
    "dropout_rates = [0.0, 0.05, 0.1]\n",
    "\n",
    "grid_search_df = pd.DataFrame(columns=[\"number_neurons\",\"number_layers\",\"dropout_rate\",\"train_rmse\", \"val_rmse\"])\n",
    "\n",
    "for neurons in number_neurons:\n",
    "    for num_layer in number_layers:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            model = Sequential()\n",
    "            for _ in range(num_layer):\n",
    "                model.add(Dense(neurons, activation='relu'))\n",
    "                if dropout_rate > 0:\n",
    "                    model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(1))\n",
    "            optimizer = Adam(learning_rate=0.01)\n",
    "            model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "            early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "    \n",
    "            # Optional: speichern der besten Gewichte\n",
    "            #checkpoint = ModelCheckpoint(\"model/NN_model_speed_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "    \n",
    "            hist = model.fit(\n",
    "                X_train_scaled, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr],\n",
    "                verbose=0\n",
    "            )\n",
    "    \n",
    "            # Ergebnisse speichern\n",
    "            min_err = min(hist.history['rmse'])\n",
    "            min_val_err = min(hist.history['val_rmse'])\n",
    "            it_df = pd.DataFrame({\n",
    "                \"number_neurons\": [neurons],\n",
    "                \"number_layers\": [num_layer],\n",
    "                \"dropout_rate\":[dropout_rate],\n",
    "                \"train_rmse\": [min_err],\n",
    "                \"val_rmse\": [min_val_err]\n",
    "            })\n",
    "            grid_search_df = pd.concat([grid_search_df, it_df], axis=0)\n",
    "            print(neurons, num_layer,dropout_rate, \"done\")\n",
    "\n",
    "# Übersicht\n",
    "grid_search_df.reset_index(drop=True, inplace=True)\n",
    "print(grid_search_df)\n",
    "best_config = grid_search_df.loc[grid_search_df['val_rmse'].idxmin()]\n",
    "best_neurons = int(best_config['number_neurons'])\n",
    "best_layers = int(best_config['number_layers'])\n",
    "best_dropout = int(best_config['dropout_rate'])\n",
    "print(best_neurons, best_layers, best_dropout)\n",
    "\n",
    "# Modell mit besten Parametern\n",
    "best_model = Sequential()\n",
    "for _ in range(best_layers):\n",
    "    best_model.add(Dense(best_neurons, activation='relu'))\n",
    "    if best_dropout > 0:\n",
    "        best_model.add(Dropout(best_dropout))\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "best_model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "checkpoint = ModelCheckpoint(\"model/NN_model_speed_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "# Training\n",
    "best_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Testbewertung\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best SPEED NN -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "770e6df0-3513-4d4a-8f5e-8bea1040e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d41bb8c-c0c6-4c9c-b240-9daeaac404bc",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eac6fea4-f5c7-44ca-b9f3-81dba385d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "flow_features_same = [\n",
    "    f'SENSOR_{sensor}_FLOW'\n",
    "    for sensor in same_sensors\n",
    "    #for i in range(nlags)\n",
    "]\n",
    "flow_features_neighbour = [\n",
    "    f'SENSOR_{sensor}_FLOW'\n",
    "    for sensor in neighbour_sensors\n",
    "    #for i in range(nlags)\n",
    "]\n",
    "speed_features_same = [\n",
    "    f'SENSOR_{sensor}_SPEED'\n",
    "    for sensor in same_sensors\n",
    "    #for i in range(nlags)\n",
    "]\n",
    "speed_features_neighbour = [\n",
    "    f'SENSOR_{sensor}_SPEED'\n",
    "    for sensor in neighbour_sensors\n",
    "    #for i in range(nlags)\n",
    "]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b908c02c-d444-49fa-8820-dc973651104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, seq_length=15, horizon=15):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length - horizon + 1):\n",
    "        Xs.append(X[i:i+seq_length])\n",
    "        ys.append(y[i+seq_length:i+seq_length+horizon])\n",
    "    return np.array(Xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "65d84553-3e22-40d2-b77c-50fbab086b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 31.4992 - rmse: 5.6124 - val_loss: 19.0745 - val_rmse: 4.3674 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 16.3062 - rmse: 4.0381 - val_loss: 18.9920 - val_rmse: 4.3580 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 16.2274 - rmse: 4.0283 - val_loss: 18.7797 - val_rmse: 4.3336 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 16.1265 - rmse: 4.0158 - val_loss: 18.7793 - val_rmse: 4.3335 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 16.0776 - rmse: 4.0097 - val_loss: 18.7620 - val_rmse: 4.3315 - learning_rate: 5.0000e-04\n",
      "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_all[flow_features_neighbour].values\n",
    "y = df_all[f'SENSOR_{target_sensor}_FLOW'].values\n",
    "\n",
    "\n",
    "\n",
    "X_seq, y_seq = create_sequences(X, y, seq_length=15, horizon=15)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "# reshape für den Scaler (2D erwartet)\n",
    "X_scaled = X_scaler.fit_transform(X_seq.reshape(-1, X_seq.shape[2])).reshape(X_seq.shape)\n",
    "#y_scaled = y_scaler.fit_transform(y_seq.reshape(-1, 1))\n",
    "X_seq=X_scaled\n",
    "#y_seq=y_scaled\n",
    "\n",
    "\n",
    "n_features = X_seq.shape[2]\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15,n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=False),\n",
    "    Dense(15)  # 15 Output-Werte für 15-Minuten-Vorhersage\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32,callbacks=[early_stop, reduce_lr, checkpoint], validation_split=0.1,verbose=1)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "201fcd02-866e-47db-afec-c7f09e80d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM (FLOW) -> RMSE: 3.936, MAE: 2.919, R2: 0.643\n",
      "LSTM Sum Forecast (FLOW) → RMSE: 35.601, MAE: 22.823, R²: 0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LSTM (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "y_test_sum = y_test.sum(axis=1)\n",
    "y_pred_sum = y_pred.sum(axis=1)\n",
    "\n",
    "# Metriken berechnen\n",
    "rmse = mean_squared_error(y_test_sum, y_pred_sum, squared=False)\n",
    "mae = mean_absolute_error(y_test_sum, y_pred_sum)\n",
    "r2 = r2_score(y_test_sum, y_pred_sum)\n",
    "\n",
    "print(f\"LSTM Sum Forecast (FLOW) → RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0e260886-11e7-4125-970f-5480370c4193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76171, 15)\n",
      "(73006, 15)\n"
     ]
    }
   ],
   "source": [
    "df_all['FLOW_future_sum'] = (\n",
    "    df_all[f'SENSOR_{target_sensor}_FLOW']\n",
    "    .rolling(15, min_periods=15)\n",
    "    .sum()\n",
    "    .shift(-14)  # damit die Summe bei t=07:02 die Werte von 07:02–07:16 enthält\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "df_all['SPEED_future_mean'] = (\n",
    "    df_all[f'SENSOR_{target_sensor}_SPEED']\n",
    "    .rolling(15, min_periods=15)\n",
    "    .mean()\n",
    "    .shift(-14)  # damit die Summe bei t=07:02 die Werte von 07:02–07:16 enthält\n",
    "    .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "print(df_all.shape)\n",
    "df_all = df_all[df_all['Datetime'].dt.time <= time(9, 45)]\n",
    "print(df_all.shape)\n",
    "\n",
    "#print(df_lagged_all[\"Datetime\"]dt.time.min(), df_lagged_all[\"Datetime\"].dt.date.max())\n",
    "#df_all.head(20)\n",
    "#print(df_lagged_all.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d4d05661-71a9-4fe3-ad35-62914fe676d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_sum(X, y, seq_length=15, horizon=15):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - seq_length - horizon + 1):\n",
    "        Xs.append(X[i:i+seq_length])\n",
    "        # statt array von 15 Werten → Summe\n",
    "        ys.append(y[i+seq_length:i+seq_length+horizon].sum())  \n",
    "    return np.array(Xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "be418ea0-8322-43ef-a06b-352e5362712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_rmse', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=3)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c7aeb5b2-c985-47cb-9599-d777b013feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1518 - rmse: 0.3896 - val_loss: 0.2617 - val_rmse: 0.5116 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1194 - rmse: 0.3455 - val_loss: 0.2489 - val_rmse: 0.4989 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1129 - rmse: 0.3361 - val_loss: 0.2693 - val_rmse: 0.5190 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1097 - rmse: 0.3313 - val_loss: 0.2553 - val_rmse: 0.5053 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1082 - rmse: 0.3290 - val_loss: 0.2957 - val_rmse: 0.5438 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1018 - rmse: 0.3191 - val_loss: 0.2295 - val_rmse: 0.4790 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0995 - rmse: 0.3154 - val_loss: 0.2269 - val_rmse: 0.4764 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0985 - rmse: 0.3139 - val_loss: 0.2345 - val_rmse: 0.4843 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0968 - rmse: 0.3112 - val_loss: 0.2328 - val_rmse: 0.4825 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0946 - rmse: 0.3076 - val_loss: 0.2372 - val_rmse: 0.4871 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0913 - rmse: 0.3021 - val_loss: 0.2305 - val_rmse: 0.4801 - learning_rate: 2.5000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0898 - rmse: 0.2997 - val_loss: 0.2327 - val_rmse: 0.4824 - learning_rate: 2.5000e-04\n",
      "\u001b[1m1880/1880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
      "LSTM 1 output (FLOW) -> RMSE: 0.436, MAE: 0.278, R2: 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "split = int(len(X) * 0.8)\n",
    "df_train, df_test = df_all[:split], df_all[split:]\n",
    "\n",
    "\n",
    "X_train = df_train[flow_features_neighbour].values\n",
    "y_train = df_train['FLOW_future_sum'].values\n",
    "X_test = df_test[flow_features_neighbour].values\n",
    "y_test = df_test['FLOW_future_sum'].values\n",
    "\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences_sum(X_train, y_train, seq_length=15, horizon=15)\n",
    "X_test_seq, y_test_seq = create_sequences_sum(X_test, y_test, seq_length=15, horizon=15)\n",
    "\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_scaler.fit_transform(X_train_seq.reshape(-1, X_train_seq.shape[2])).reshape(X_train_seq.shape)\n",
    "X_test_scaled  = X_scaler.transform(X_test_seq.reshape(-1, X_test_seq.shape[2])).reshape(X_test_seq.shape)\n",
    "\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_seq.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_seq.reshape(-1, 1))\n",
    "\n",
    "\n",
    "n_features = X_train_scaled.shape[2]\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model/LSTM_model_flow_neighbour_best.keras\", monitor='val_rmse', save_best_only=True, mode='min')\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(15, n_features), return_sequences=True),\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(64, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "#model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1,verbose=1)\n",
    "hist = model.fit(\n",
    "                X_train_scaled, y_train_scaled,\n",
    "                validation_split=0.2,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "rmse = mean_squared_error(y_test_scaled, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test_scaled, y_pred)\n",
    "r2 = r2_score(y_test_scaled, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e6c7786f-df0a-4a68-9132-9eddab1a871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "LSTM 1 output (FLOW) -> RMSE: 0.390, MAE: 0.266, R2: 0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johanna\\anaconda3\\envs\\AI_project\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_test_peak= df_test.set_index(\"Datetime\").between_time(\"07:15\", \"08:30\").reset_index()\n",
    "X_test_peak = df_test_peak[flow_features_neighbour].values\n",
    "y_test_peak = df_test_peak['FLOW_future_sum'].values\n",
    "X_test_seq_peak, y_test_seq_peak = create_sequences_sum(X_test_peak, y_test_peak, seq_length=15, horizon=15)\n",
    "\n",
    "X_test_peak_scaled  = X_scaler.transform(X_test_seq_peak.reshape(-1, X_test_seq_peak.shape[2])).reshape(X_test_seq_peak.shape)\n",
    "y_test_peak_scaled  = y_scaler.transform(y_test_seq_peak.reshape(-1, 1))\n",
    "\n",
    "y_pred = model.predict(X_test_peak_scaled)\n",
    "\n",
    "rmse = mean_squared_error(y_test_peak_scaled, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test_peak_scaled, y_pred)\n",
    "r2 = r2_score(y_test_peak_scaled, y_pred)\n",
    "\n",
    "print(f\"LSTM 1 output (FLOW) -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1ae4d-83ff-4e3f-bbf6-cb66a1088180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
